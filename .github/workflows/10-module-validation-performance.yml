---
name: üî¨ Module Architecture Validation & Performance

# Validates module architecture and profiles performance
# Runs on PRs and releases to ensure module quality

'on':
  workflow_call:
  
  push:
    branches: [main]
    paths:
      - 'aithercore/**/*.psm1'
      - 'AitherZero.psm1'
      - 'AitherZero.psd1'
  workflow_dispatch:
    inputs:
      detailed_report:
        description: 'Generate detailed performance report'
        type: boolean
        default: true
      optimize:
        description: 'Include optimization recommendations'
        type: boolean
        default: true

permissions:
  contents: write
  pull-requests: write
  checks: write

concurrency:
  group: module-validation-${{ github.ref }}
  cancel-in-progress: true

env:
  AITHERZERO_CI: true
  AITHERZERO_NONINTERACTIVE: true
  AITHERZERO_SUPPRESS_BANNER: true

jobs:
  validate-architecture:
    name: üèóÔ∏è Validate Module Architecture
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      validation-status: ${{ steps.validate.outputs.status }}
      script-count: ${{ steps.validate.outputs.script_count }}
      passed-count: ${{ steps.validate.outputs.passed_count }}
      failed-count: ${{ steps.validate.outputs.failed_count }}
      warning-count: ${{ steps.validate.outputs.warning_count }}

    steps:
      - name: üì• Checkout
        uses: actions/checkout@v4

      - name: üîß Bootstrap Environment
        shell: pwsh
        run: |
          Write-Host "üöÄ Bootstrapping AitherZero..." -ForegroundColor Cyan
          ./bootstrap.ps1 -Mode New -InstallProfile Minimal

      - name: üì¶ Load Module
        shell: pwsh
        run: |
          $env:AITHERZERO_DISABLE_TRANSCRIPT = '1'
          Import-Module ./AitherZero.psd1 -Force
          Write-Host "‚úÖ Module loaded successfully" -ForegroundColor Green

      - name: üîç Validate Automation Scripts
        id: validate
        shell: pwsh
        run: |
          Write-Host "üîç Validating all automation scripts..." -ForegroundColor Cyan
          
          # Run validation
          $exitCode = 0
          try {
            & ./library/automation-scripts/0950_Validate-AllAutomationScripts.ps1 -Fast
            $exitCode = $LASTEXITCODE
          } catch {
            Write-Host "‚ùå Validation failed: $_" -ForegroundColor Red
            $exitCode = 1
          }
          
          # Parse results
          if (Test-Path 'reports/validation-results.json') {
            $results = Get-Content 'reports/validation-results.json' | ConvertFrom-Json
            $scriptCount = $results.Count
            $passed = ($results | Where-Object { $_.Status -eq 'Pass' }).Count
            $failed = ($results | Where-Object { $_.Status -eq 'Fail' }).Count
            $warnings = ($results | Where-Object { $_.Status -eq 'Warn' }).Count
            
            echo "script_count=$scriptCount" >> $env:GITHUB_OUTPUT
            echo "passed_count=$passed" >> $env:GITHUB_OUTPUT
            echo "failed_count=$failed" >> $env:GITHUB_OUTPUT
            echo "warning_count=$warnings" >> $env:GITHUB_OUTPUT
            echo "status=$(if ($failed -eq 0) { 'success' } else { 'failure' })" >> $env:GITHUB_OUTPUT
            
            Write-Host "üìä Validation Results:" -ForegroundColor Cyan
            Write-Host "  Total Scripts: $scriptCount" -ForegroundColor White
            Write-Host "  ‚úÖ Passed: $passed" -ForegroundColor Green
            Write-Host "  ‚ùå Failed: $failed" -ForegroundColor $(if ($failed -eq 0) { 'Green' } else { 'Red' })
            Write-Host "  ‚ö†Ô∏è  Warnings: $warnings" -ForegroundColor Yellow
          }
          
          exit $exitCode

      - name: üì§ Upload Validation Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: validation-results
          path: reports/validation-results.json
          retention-days: 30

      - name: üí¨ Comment on PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            let resultsFile = 'reports/validation-results.json';
            let comment = '## üîç Automation Script Validation\n\n';
            
            if (fs.existsSync(resultsFile)) {
              const results = JSON.parse(fs.readFileSync(resultsFile, 'utf8'));
              const passed = results.filter(r => r.Status === 'Pass').length;
              const failed = results.filter(r => r.Status === 'Fail').length;
              const warnings = results.filter(r => r.Status === 'Warn').length;
              
              comment += `**Results:**\n`;
              comment += `- Total Scripts: ${results.length}\n`;
              comment += `- ‚úÖ Passed: ${passed}\n`;
              comment += `- ‚ùå Failed: ${failed}\n`;
              comment += `- ‚ö†Ô∏è Warnings: ${warnings}\n\n`;
              
              if (failed > 0) {
                comment += `### ‚ùå Failed Scripts\n\n`;
                results.filter(r => r.Status === 'Fail').forEach(r => {
                  comment += `- **${r.Script}**\n`;
                  r.Issues.forEach(issue => comment += `  - ${issue}\n`);
                });
              }
              
              if (warnings > 0) {
                comment += `\n### ‚ö†Ô∏è Scripts with Warnings\n\n`;
                const warnScripts = results.filter(r => r.Status === 'Warn');
                warnScripts.slice(0, 5).forEach(r => {
                  comment += `- **${r.Script}**: ${r.Issues[0]}\n`;
                });
                if (warnScripts.length > 5) {
                  comment += `\n_... and ${warnScripts.length - 5} more_\n`;
                }
              }
            } else {
              comment += '‚ö†Ô∏è Validation results file not found.\n';
            }
            
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(c => 
              c.user.type === 'Bot' && c.body.includes('Automation Script Validation')
            );
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

  profile-performance:
    name: ‚ö° Profile Module Performance
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      load-time: ${{ steps.profile.outputs.load_time }}
      memory-usage: ${{ steps.profile.outputs.memory_usage }}
      rating: ${{ steps.profile.outputs.rating }}
      module-count: ${{ steps.profile.outputs.module_count }}

    steps:
      - name: üì• Checkout
        uses: actions/checkout@v4

      - name: üîß Bootstrap Environment
        shell: pwsh
        run: |
          Write-Host "üöÄ Bootstrapping AitherZero..." -ForegroundColor Cyan
          ./bootstrap.ps1 -Mode New -InstallProfile Minimal

      - name: ‚ö° Profile Performance
        id: profile
        shell: pwsh
        run: |
          Write-Host "‚ö° Profiling module performance..." -ForegroundColor Cyan
          
          $detailed = '${{ github.event.inputs.detailed_report }}' -eq 'true' -or $env:GITHUB_EVENT_NAME -eq 'pull_request'
          $optimize = '${{ github.event.inputs.optimize }}' -eq 'true' -or $env:GITHUB_EVENT_NAME -eq 'pull_request'
          
          $params = @()
          if ($detailed) { $params += '-Detailed' }
          if ($optimize) { $params += '-Optimize' }
          
          $exitCode = 0
          try {
            & ./library/automation-scripts/0529_Profile-ModulePerformance.ps1 @params
            $exitCode = $LASTEXITCODE
          } catch {
            Write-Host "‚ùå Profiling failed: $_" -ForegroundColor Red
            $exitCode = 1
          }
          
          # Parse results
          if (Test-Path 'reports/performance-metrics.json') {
            $metrics = Get-Content 'reports/performance-metrics.json' | ConvertFrom-Json
            
            $loadTime = $metrics.ModuleLoadTime.TotalSeconds
            $memoryMB = $metrics.Memory.IncreaseMB
            $rating = $metrics.Performance.LoadTimeRating
            $moduleCount = $metrics.Modules.Total
            
            echo "load_time=${loadTime}s" >> $env:GITHUB_OUTPUT
            echo "memory_usage=${memoryMB}MB" >> $env:GITHUB_OUTPUT
            echo "rating=$rating" >> $env:GITHUB_OUTPUT
            echo "module_count=$moduleCount" >> $env:GITHUB_OUTPUT
            
            Write-Host "üìä Performance Results:" -ForegroundColor Cyan
            Write-Host "  Load Time: ${loadTime}s ($rating)" -ForegroundColor White
            Write-Host "  Memory: ${memoryMB}MB" -ForegroundColor White
            Write-Host "  Modules: $moduleCount" -ForegroundColor White
          }
          
          exit $exitCode

      - name: üì§ Upload Performance Metrics
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-metrics
          path: |
            reports/performance-metrics.json
            reports/performance-dashboard.json
          retention-days: 90

      - name: üí¨ Comment Performance Results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            let metricsFile = 'reports/performance-metrics.json';
            let comment = '## ‚ö° Module Performance Profile\n\n';
            
            if (fs.existsSync(metricsFile)) {
              const metrics = JSON.parse(fs.readFileSync(metricsFile, 'utf8'));
              
              const loadTime = metrics.ModuleLoadTime.TotalSeconds;
              const memoryMB = metrics.Memory.IncreaseMB;
              const loadRating = metrics.Performance.LoadTimeRating;
              const memoryRating = metrics.Performance.MemoryRating;
              const moduleCount = metrics.Modules.Total;
              const commandCount = metrics.Modules.ExportedCommands;
              
              const ratingEmoji = {
                'Excellent': 'üü¢',
                'Good': 'üü°',
                'Fair': 'üü†',
                'Poor': 'üî¥'
              };
              
              comment += `### Performance Metrics\n\n`;
              comment += `| Metric | Value | Rating |\n`;
              comment += `|--------|-------|--------|\n`;
              comment += `| **Load Time** | ${loadTime}s | ${ratingEmoji[loadRating]} ${loadRating} |\n`;
              comment += `| **Memory Usage** | ${memoryMB}MB | ${ratingEmoji[memoryRating]} ${memoryRating} |\n`;
              comment += `| **Modules Loaded** | ${moduleCount} | ‚úÖ |\n`;
              comment += `| **Exported Commands** | ${commandCount} | ‚úÖ |\n\n`;
              
              if (metrics.TopSlowestModules && metrics.TopSlowestModules.length > 0) {
                comment += `### üêå Top 5 Slowest Modules\n\n`;
                metrics.TopSlowestModules.slice(0, 5).forEach((m, i) => {
                  comment += `${i+1}. **${m.Module}**: ${m.TimeMs}ms\n`;
                });
              }
              
              comment += `\n_Profiled on: ${metrics.Environment.OS} (PowerShell ${metrics.Environment.PSVersion})_\n`;
            } else {
              comment += '‚ö†Ô∏è Performance metrics file not found.\n';
            }
            
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(c => 
              c.user.type === 'Bot' && c.body.includes('Module Performance Profile')
            );
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

  update-dashboard:
    name: üìä Update Dashboard
    needs: [validate-architecture, profile-performance]
    runs-on: ubuntu-latest
    if: always() && github.event_name == 'push' && github.ref == 'refs/heads/main'
    timeout-minutes: 5

    steps:
      - name: üì• Checkout
        uses: actions/checkout@v4

      - name: üì• Download Artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: üìä Generate Combined Dashboard
        shell: pwsh
        run: |
          $dashboard = @{
            timestamp = Get-Date -Format 'yyyy-MM-dd HH:mm:ss UTC'
            branch = '${{ github.ref_name }}'
            commit = '${{ github.sha }}'.Substring(0, 7)
            validation = @{
              scripts = '${{ needs.validate-architecture.outputs.script-count }}'
              passed = '${{ needs.validate-architecture.outputs.passed-count }}'
              failed = '${{ needs.validate-architecture.outputs.failed-count }}'
              warnings = '${{ needs.validate-architecture.outputs.warning-count }}'
              status = '${{ needs.validate-architecture.outputs.validation-status }}'
            }
            performance = @{
              loadTime = '${{ needs.profile-performance.outputs.load-time }}'
              memory = '${{ needs.profile-performance.outputs.memory-usage }}'
              rating = '${{ needs.profile-performance.outputs.rating }}'
              modules = '${{ needs.profile-performance.outputs.module-count }}'
            }
          }
          
          $dashboard | ConvertTo-Json -Depth 10 | Out-File 'reports/module-health-dashboard.json' -Encoding utf8
          Write-Host "‚úÖ Dashboard generated" -ForegroundColor Green

      - name: üì§ Upload to Reports
        uses: actions/upload-artifact@v4
        with:
          name: module-health-dashboard
          path: reports/module-health-dashboard.json
          retention-days: 90

  check-status:
    name: ‚úÖ Final Status Check
    needs: [validate-architecture, profile-performance]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - name: ‚úÖ Verify Results
        shell: pwsh
        run: |
          $validationStatus = '${{ needs.validate-architecture.outputs.validation-status }}'
          $failedCount = [int]'${{ needs.validate-architecture.outputs.failed-count }}'
          
          Write-Host "=== Final Status ===" -ForegroundColor Cyan
          Write-Host "Validation: $validationStatus" -ForegroundColor $(if ($validationStatus -eq 'success') { 'Green' } else { 'Red' })
          Write-Host "Failed Scripts: $failedCount" -ForegroundColor $(if ($failedCount -eq 0) { 'Green' } else { 'Red' })
          
          if ($validationStatus -ne 'success' -or $failedCount -gt 0) {
            Write-Host "‚ùå Workflow failed - validation issues detected" -ForegroundColor Red
            exit 1
          }
          
          Write-Host "‚úÖ All checks passed!" -ForegroundColor Green
