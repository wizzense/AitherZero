---
name: âš¡ Parallel Testing (High Performance)

# High-performance parallel test execution across multiple runners
# Tests are split by range and executed concurrently, then consolidated

on:
  push:
    branches: [main, develop, dev, dev-staging]
    paths:
      - 'domains/**'
      - 'automation-scripts/**'
      - 'tests/**'
      - '**.ps1'
      - '**.psm1'
  pull_request:
    branches: [main, develop, dev, dev-staging]
  workflow_dispatch:
    inputs:
      test_filter:
        description: 'Test filter (all, unit, integration, domains)'
        type: choice
        options:
          - all
          - unit
          - integration
          - domains
        default: 'all'

permissions:
  contents: read
  checks: write
  pull-requests: write

# Allow parallel execution across different test suites
concurrency:
  group: parallel-tests-${{ github.ref }}-${{ github.run_number }}
  cancel-in-progress: false  # Keep running - we want parallel jobs

env:
  AITHERZERO_CI: true
  AITHERZERO_NONINTERACTIVE: true

jobs:
  # Fast preparation job - sets up for parallel execution
  prepare:
    name: ğŸ¯ Prepare Test Matrix
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      unit-ranges: ${{ steps.matrix.outputs.unit-ranges }}
      domain-modules: ${{ steps.matrix.outputs.domain-modules }}
      integration-suites: ${{ steps.matrix.outputs.integration-suites }}
    
    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
      
      - name: ğŸ”§ Quick Bootstrap
        shell: pwsh
        run: |
          ./bootstrap.ps1 -Mode New -InstallProfile Minimal
      
      - name: ğŸ¯ Generate Test Matrix
        id: matrix
        shell: pwsh
        run: |
          # Unit test ranges (by script number ranges)
          $unitRanges = @(
            '0000-0099',
            '0100-0199',
            '0200-0299',
            '0400-0499',
            '0500-0599',
            '0700-0799',
            '0800-0899',
            '0900-0999'
          )
          
          # Domain modules - ONLY modules that have test directories
          $domainModules = @(
            'configuration',
            'documentation',
            'infrastructure',
            'security',
            'testing',
            'utilities'
          )
          
          # Integration test suites - ONLY suites that exist
          $integrationSuites = @(
            'automation-scripts'
          )
          
          # Output as JSON arrays for matrix
          $unitRangesJson = $unitRanges | ConvertTo-Json -Compress
          $domainModulesJson = $domainModules | ConvertTo-Json -Compress
          $integrationSuitesJson = $integrationSuites | ConvertTo-Json -Compress
          
          "unit-ranges=$unitRangesJson" >> $env:GITHUB_OUTPUT
          "domain-modules=$domainModulesJson" >> $env:GITHUB_OUTPUT
          "integration-suites=$integrationSuitesJson" >> $env:GITHUB_OUTPUT
          
          Write-Host "âœ… Test matrix generated" -ForegroundColor Green
          Write-Host "   Unit ranges: $($unitRanges.Count)" -ForegroundColor Cyan
          Write-Host "   Domain modules: $($domainModules.Count)" -ForegroundColor Cyan
          Write-Host "   Integration suites: $($integrationSuites.Count)" -ForegroundColor Cyan

  # Parallel unit tests by script number range
  unit-tests-parallel:
    name: ğŸ§ª Unit Tests [${{ matrix.range }}]
    needs: prepare
    runs-on: ubuntu-latest
    timeout-minutes: 10
    if: github.event.inputs.test_filter == 'all' || github.event.inputs.test_filter == 'unit' || github.event.inputs.test_filter == ''
    
    strategy:
      fail-fast: false  # Continue all jobs even if one fails
      max-parallel: 8   # Run up to 8 jobs simultaneously
      matrix:
        range: ${{ fromJson(needs.prepare.outputs.unit-ranges) }}
    
    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
      
      - name: ğŸ”§ Bootstrap
        shell: pwsh
        timeout-minutes: 3
        run: |
          ./bootstrap.ps1 -Mode New -InstallProfile Minimal
      
      - name: ğŸ§ª Run Unit Tests [${{ matrix.range }}]
        id: run-tests
        shell: pwsh
        continue-on-error: true
        timeout-minutes: 5
        run: |
          Write-Host "âš¡ Running unit tests for range: ${{ matrix.range }}" -ForegroundColor Cyan
          
          $testPath = "./tests/unit/automation-scripts/${{ matrix.range }}"
          
          if (Test-Path $testPath) {
            $config = New-PesterConfiguration
            $config.Run.Path = $testPath
            $config.Run.Exit = $false
            $config.Run.PassThru = $true
            $config.Output.Verbosity = 'Normal'
            $config.TestResult.Enabled = $true
            $config.TestResult.OutputPath = "./tests/results/UnitTests-${{ matrix.range }}.xml"
            $config.TestResult.OutputFormat = 'NUnitXml'
            
            $result = Invoke-Pester -Configuration $config
            
            Write-Host "âœ… Tests completed for ${{ matrix.range }}" -ForegroundColor Green
            Write-Host "   Passed: $($result.PassedCount)" -ForegroundColor Green
            Write-Host "   Failed: $($result.FailedCount)" -ForegroundColor $(if ($result.FailedCount -gt 0) { 'Red' } else { 'Green' })
            Write-Host "   Skipped: $($result.SkippedCount)" -ForegroundColor Yellow
            
            # Mark step as failed but don't exit (continue-on-error allows continuation)
            if ($result.FailedCount -gt 0) {
              Write-Host "##vso[task.complete result=Failed;]Tests failed"
              exit 1
            }
          } else {
            Write-Host "â­ï¸  No tests found for range ${{ matrix.range }}" -ForegroundColor Yellow
          }
      
      - name: ğŸ“Š Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-tests-${{ matrix.range }}
          path: ./tests/results/UnitTests-${{ matrix.range }}.xml
          retention-days: 7
          if-no-files-found: warn

  # Parallel domain module tests
  domain-tests-parallel:
    name: ğŸ—ï¸ Domain Tests [${{ matrix.module }}]
    needs: prepare
    runs-on: ubuntu-latest
    timeout-minutes: 10
    if: github.event.inputs.test_filter == 'all' || github.event.inputs.test_filter == 'domains' || github.event.inputs.test_filter == ''
    
    strategy:
      fail-fast: false
      max-parallel: 8
      matrix:
        module: ${{ fromJson(needs.prepare.outputs.domain-modules) }}
    
    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
      
      - name: ğŸ”§ Bootstrap
        shell: pwsh
        timeout-minutes: 3
        run: |
          ./bootstrap.ps1 -Mode New -InstallProfile Minimal
      
      - name: ğŸ—ï¸ Run Domain Tests [${{ matrix.module }}]
        id: run-tests
        shell: pwsh
        continue-on-error: true
        timeout-minutes: 5
        run: |
          Write-Host "âš¡ Running domain tests for: ${{ matrix.module }}" -ForegroundColor Cyan
          
          $testPath = "./tests/domains/${{ matrix.module }}"
          
          if (Test-Path $testPath) {
            $config = New-PesterConfiguration
            $config.Run.Path = $testPath
            $config.Run.Exit = $false
            $config.Run.PassThru = $true
            $config.Output.Verbosity = 'Normal'
            $config.TestResult.Enabled = $true
            $config.TestResult.OutputPath = "./tests/results/DomainTests-${{ matrix.module }}.xml"
            $config.TestResult.OutputFormat = 'NUnitXml'
            
            $result = Invoke-Pester -Configuration $config
            
            Write-Host "âœ… Tests completed for ${{ matrix.module }}" -ForegroundColor Green
            Write-Host "   Passed: $($result.PassedCount)" -ForegroundColor Green
            Write-Host "   Failed: $($result.FailedCount)" -ForegroundColor $(if ($result.FailedCount -gt 0) { 'Red' } else { 'Green' })
            Write-Host "   Skipped: $($result.SkippedCount)" -ForegroundColor Yellow
            
            # Mark step as failed but don't exit (continue-on-error allows continuation)
            if ($result.FailedCount -gt 0) {
              Write-Host "##vso[task.complete result=Failed;]Tests failed"
              exit 1
            }
          } else {
            Write-Host "â­ï¸  No tests found for module ${{ matrix.module }}" -ForegroundColor Yellow
          }
      
      - name: ğŸ“Š Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: domain-tests-${{ matrix.module }}
          path: ./tests/results/DomainTests-${{ matrix.module }}.xml
          retention-days: 7
          if-no-files-found: warn

  # Parallel integration tests
  integration-tests-parallel:
    name: ğŸ”— Integration Tests [${{ matrix.suite }}]
    needs: prepare
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: github.event.inputs.test_filter == 'all' || github.event.inputs.test_filter == 'integration' || github.event.inputs.test_filter == ''
    
    strategy:
      fail-fast: false
      max-parallel: 3
      matrix:
        suite: ${{ fromJson(needs.prepare.outputs.integration-suites) }}
    
    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
      
      - name: ğŸ”§ Bootstrap
        shell: pwsh
        timeout-minutes: 3
        run: |
          ./bootstrap.ps1 -Mode New -InstallProfile Minimal
      
      - name: ğŸ”— Run Integration Tests [${{ matrix.suite }}]
        id: run-tests
        shell: pwsh
        continue-on-error: true
        timeout-minutes: 10
        run: |
          Write-Host "âš¡ Running integration tests for: ${{ matrix.suite }}" -ForegroundColor Cyan
          
          $testPath = "./tests/integration/${{ matrix.suite }}"
          
          if (Test-Path $testPath) {
            $config = New-PesterConfiguration
            $config.Run.Path = $testPath
            $config.Run.Exit = $false
            $config.Run.PassThru = $true
            $config.Output.Verbosity = 'Normal'
            $config.TestResult.Enabled = $true
            $config.TestResult.OutputPath = "./tests/results/IntegrationTests-${{ matrix.suite }}.xml"
            $config.TestResult.OutputFormat = 'NUnitXml'
            
            $result = Invoke-Pester -Configuration $config
            
            Write-Host "âœ… Tests completed for ${{ matrix.suite }}" -ForegroundColor Green
            Write-Host "   Passed: $($result.PassedCount)" -ForegroundColor Green
            Write-Host "   Failed: $($result.FailedCount)" -ForegroundColor $(if ($result.FailedCount -gt 0) { 'Red' } else { 'Green' })
            Write-Host "   Skipped: $($result.SkippedCount)" -ForegroundColor Yellow
            
            # Mark step as failed but don't exit (continue-on-error allows continuation)
            if ($result.FailedCount -gt 0) {
              Write-Host "##vso[task.complete result=Failed;]Tests failed"
              exit 1
            }
          } else {
            Write-Host "â­ï¸  No tests found for suite ${{ matrix.suite }}" -ForegroundColor Yellow
          }
      
      - name: ğŸ“Š Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-tests-${{ matrix.suite }}
          path: ./tests/results/IntegrationTests-${{ matrix.suite }}.xml
          retention-days: 7
          if-no-files-found: warn

  # Static analysis (runs in parallel with tests)
  static-analysis:
    name: ğŸ” Static Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 10
    if: github.event.inputs.test_filter == 'all' || github.event.inputs.test_filter == ''
    
    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
      
      - name: ğŸ”§ Bootstrap
        shell: pwsh
        timeout-minutes: 3
        run: |
          ./bootstrap.ps1 -Mode New -InstallProfile Minimal
      
      - name: ğŸ” Syntax Validation
        shell: pwsh
        timeout-minutes: 2
        run: |
          Write-Host "âš¡ Running syntax validation" -ForegroundColor Cyan
          ./automation-scripts/0407_Validate-Syntax.ps1 -All
      
      - name: ğŸ” PSScriptAnalyzer
        shell: pwsh
        timeout-minutes: 5
        continue-on-error: true
        run: |
          Write-Host "âš¡ Running PSScriptAnalyzer" -ForegroundColor Cyan
          ./automation-scripts/0404_Run-PSScriptAnalyzer.ps1
      
      - name: ğŸ“Š Upload Analysis Results
        if: always() && hashFiles('./tests/analysis/*') != ''
        uses: actions/upload-artifact@v4
        with:
          name: static-analysis
          path: ./tests/analysis/*
          retention-days: 7

  # Consolidation job - runs after all parallel jobs complete
  consolidate-results:
    name: ğŸ“Š Consolidate & Report
    needs: [unit-tests-parallel, domain-tests-parallel, integration-tests-parallel, static-analysis]
    runs-on: ubuntu-latest
    timeout-minutes: 10
    if: always()  # Run even if some tests failed
    
    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
      
      - name: ğŸ”§ Bootstrap
        shell: pwsh
        timeout-minutes: 3
        run: |
          ./bootstrap.ps1 -Mode New -InstallProfile Minimal
      
      - name: ğŸ“¥ Download All Test Results
        uses: actions/download-artifact@v4
        with:
          path: ./tests/results-consolidated
      
      - name: ğŸ“Š Consolidate Results
        id: consolidate
        shell: pwsh
        continue-on-error: true
        run: |
          Write-Host "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”" -ForegroundColor Cyan
          Write-Host "ğŸ“Š Consolidating Parallel Test Results" -ForegroundColor Cyan
          Write-Host "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”" -ForegroundColor Cyan
          
          $allResults = Get-ChildItem -Path "./tests/results-consolidated" -Recurse -Filter "*.xml"
          
          Write-Host "Found $($allResults.Count) test result files" -ForegroundColor Cyan
          
          $totalPassed = 0
          $totalFailed = 0
          $totalSkipped = 0
          
          foreach ($file in $allResults) {
            try {
              [xml]$xml = Get-Content $file.FullName
              $testRun = $xml.'test-results'
              if ($testRun) {
                $totalPassed += [int]$testRun.total - [int]$testRun.failures - [int]$testRun.ignored
                $totalFailed += [int]$testRun.failures
                $totalSkipped += [int]$testRun.ignored
              }
            } catch {
              Write-Host "âš ï¸  Could not parse $($file.Name): $_" -ForegroundColor Yellow
            }
          }
          
          Write-Host ""
          Write-Host "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•" -ForegroundColor Cyan
          Write-Host "   PARALLEL TEST EXECUTION COMPLETE" -ForegroundColor Green
          Write-Host "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•" -ForegroundColor Cyan
          Write-Host "   âœ… Passed:  $totalPassed" -ForegroundColor Green
          Write-Host "   âŒ Failed:  $totalFailed" -ForegroundColor $(if ($totalFailed -gt 0) { 'Red' } else { 'Green' })
          Write-Host "   â­ï¸  Skipped: $totalSkipped" -ForegroundColor Yellow
          Write-Host "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•" -ForegroundColor Cyan
          Write-Host ""
          
          # Set outputs
          "total-passed=$totalPassed" >> $env:GITHUB_OUTPUT
          "total-failed=$totalFailed" >> $env:GITHUB_OUTPUT
          "total-skipped=$totalSkipped" >> $env:GITHUB_OUTPUT
          
          # Mark as failed if tests failed (but continue-on-error allows subsequent steps)
          if ($totalFailed -gt 0) {
            Write-Host "âŒ Some tests failed - marking step as failed" -ForegroundColor Red
            exit 1
          }
      
      - name: ğŸ“Š Publish Test Report
        uses: dorny/test-reporter@v1
        if: always()
        continue-on-error: true
        with:
          name: 'âš¡ Parallel Test Results'
          path: './tests/results-consolidated/**/*.xml'
          reporter: 'dotnet-trx'
          fail-on-error: false
      
      - name: ğŸ’¬ Comment on PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        env:
          PASSED: ${{ steps.consolidate.outputs.total-passed }}
          FAILED: ${{ steps.consolidate.outputs.total-failed }}
          SKIPPED: ${{ steps.consolidate.outputs.total-skipped }}
        with:
          script: |
            const script = require('./.github/scripts/generate-test-comment.js');
            const mockCore = {
              getInput: (name) => {
                const inputs = {
                  'passed': process.env.PASSED,
                  'failed': process.env.FAILED,
                  'skipped': process.env.SKIPPED
                };
                return inputs[name] || '';
              }
            };
            return await script({github, context, core: mockCore});
      
      - name: âœ… Final Status Check
        if: always()
        shell: pwsh
        run: |
          $failed = "${{ steps.consolidate.outputs.total-failed }}"
          if ($failed -and $failed -gt 0) {
            Write-Host "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”" -ForegroundColor Red
            Write-Host "âŒ WORKFLOW FAILED: $failed test(s) failed" -ForegroundColor Red
            Write-Host "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”" -ForegroundColor Red
            Write-Host ""
            Write-Host "This failure is informational and does NOT block merging." -ForegroundColor Yellow
            Write-Host "Please review failed tests and address issues before merging." -ForegroundColor Yellow
            Write-Host ""
            exit 1
          } else {
            Write-Host "âœ… All checks passed!" -ForegroundColor Green
          }
