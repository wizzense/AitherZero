---
name: 'Phase 2 - Intelligent Issue Creation'

# Comprehensive automated issue creation system that captures ALL failure types
# and creates intelligent, deduplicated issues with agent routing and rich context
#
# IMPORTANT: Issue creation is RESTRICTED to specific PR contexts:
# - Only creates issues for PRs from dev/develop â†’ main branch
# - Manual workflow_dispatch runs are always allowed
# - Scheduled runs are always allowed
# - Direct pushes to main/dev branches are allowed
#
# This prevents issue spam for feature branches and ensures issues are only
# created for release-candidate and production-bound changes.

on:
  workflow_run:
    workflows:
      - "ğŸ§ª Comprehensive Test Execution"
      - "PR Validation"
      - "Quality Validation"
    types: [completed]

  schedule:
    # Daily analysis to catch any missed failures
    - cron: '0 3 * * *'  # 3 AM UTC daily

  workflow_dispatch:
    inputs:
      dry_run:
        description: 'Dry run - preview issues without creating them'
        type: boolean
        default: false
      force_analysis:
        description: 'Force re-analysis even if no new failures'
        type: boolean
        default: false

permissions:
  contents: read
  issues: write
  actions: read
  checks: write
  pull-requests: write

concurrency:
  group: phase2-issue-creation-${{ github.run_id }}
  cancel-in-progress: false  # Don't cancel - we want all failure analysis to complete

env:
  ISSUE_STATE_DIR: ./reports/issue-state

jobs:
  check-pr-context:
    name: ğŸ” Check PR Context (devâ†’main only)
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_run' || github.event_name == 'workflow_dispatch' || github.event_name == 'schedule'
    outputs:
      should-create-issues: ${{ steps.check.outputs.should-create-issues }}
      pr-context: ${{ steps.check.outputs.pr-context }}

    steps:
      - name: ğŸ” Check if PR is devâ†’main
        id: check
        uses: actions/github-script@v7
        with:
          script: |
            const eventName = context.eventName;

            // Always allow manual runs and scheduled runs
            if (eventName === 'workflow_dispatch' || eventName === 'schedule') {
              console.log('âœ… Manual or scheduled run - allowing issue creation');
              core.setOutput('should-create-issues', 'true');
              core.setOutput('pr-context', JSON.stringify({ type: 'manual', allowed: true }));
              return;
            }

            // For workflow_run events, check the PR context
            if (eventName === 'workflow_run') {
              const workflowRun = context.payload.workflow_run;

              // Get the pull requests associated with this workflow run
              const pullRequests = workflowRun.pull_requests || [];

              if (pullRequests.length === 0) {
                // Not a PR - could be a direct push to main/dev
                console.log('â„¹ï¸ No PR associated with this workflow run');

                // Check if it's a push to main or dev branch
                const headBranch = workflowRun.head_branch;
                if (headBranch === 'main' || headBranch === 'develop' || headBranch === 'dev') {
                  console.log(`âœ… Direct push to ${headBranch} - allowing issue creation`);
                  core.setOutput('should-create-issues', 'true');
                  core.setOutput('pr-context', JSON.stringify({
                    type: 'push',
                    branch: headBranch,
                    allowed: true
                  }));
                } else {
                  console.log(`âŒ Push to ${headBranch} - skipping issue creation`);
                  core.setOutput('should-create-issues', 'false');
                  core.setOutput('pr-context', JSON.stringify({
                    type: 'push',
                    branch: headBranch,
                    allowed: false
                  }));
                }
                return;
              }

              // Check each PR - we only want devâ†’main PRs
              for (const pr of pullRequests) {
                console.log(`Checking PR #${pr.number}: ${pr.head.ref} â†’ ${pr.base.ref}`);

                // Check if this is a devâ†’main PR
                const baseBranch = pr.base.ref;
                const headBranch = pr.head.ref;

                if (baseBranch === 'main' && (headBranch === 'dev' || headBranch === 'develop')) {
                  console.log(`âœ… Found devâ†’main PR #${pr.number} - allowing issue creation`);
                  core.setOutput('should-create-issues', 'true');
                  core.setOutput('pr-context', JSON.stringify({
                    type: 'pr',
                    number: pr.number,
                    base: baseBranch,
                    head: headBranch,
                    allowed: true
                  }));
                  return;
                }
              }

              // No matching PR found
              console.log('âŒ No devâ†’main PR found - skipping issue creation');
              console.log('Issue creation is only enabled for PRs from dev/develop to main');
              core.setOutput('should-create-issues', 'false');
              core.setOutput('pr-context', JSON.stringify({
                type: 'pr',
                allowed: false,
                reason: 'Not a devâ†’main PR'
              }));
            }

  comprehensive-failure-analysis:
    name: ğŸ” Comprehensive Failure Analysis
    runs-on: ubuntu-latest
    needs: check-pr-context
    if: needs.check-pr-context.outputs.should-create-issues == 'true'

    outputs:
      has-failures: ${{ steps.analysis.outputs.has-failures }}
      analysis-artifact: ${{ steps.analysis.outputs.analysis-artifact }}

    steps:
      - name: ğŸ“¥ Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ“‹ Log PR Context
        shell: pwsh
        run: |
          Write-Host "ğŸ” PR Context Information:" -ForegroundColor Cyan
          $prContext = '${{ needs.check-pr-context.outputs.pr-context }}' | ConvertFrom-Json
          Write-Host "  Type: $($prContext.type)" -ForegroundColor White
          if ($prContext.number) {
            Write-Host "  PR Number: $($prContext.number)" -ForegroundColor White
            Write-Host "  Base Branch: $($prContext.base)" -ForegroundColor White
            Write-Host "  Head Branch: $($prContext.head)" -ForegroundColor White
          } elseif ($prContext.branch) {
            Write-Host "  Branch: $($prContext.branch)" -ForegroundColor White
          }
          Write-Host "  Allowed: $($prContext.allowed)" -ForegroundColor $(if ($prContext.allowed) { 'Green' } else { 'Red' })

      - name: ğŸ“Š Download Workflow Artifacts
        if: github.event_name == 'workflow_run'
        uses: dawidd6/action-download-artifact@v6
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          run_id: ${{ github.event.workflow_run.id }}
          path: ./artifacts
        continue-on-error: true

      - name: ğŸ“¥ Download Existing Issue State
        uses: actions/download-artifact@v4
        with:
          name: issue-state-db
          path: ${{ env.ISSUE_STATE_DIR }}
        continue-on-error: true

      - name: ğŸ” Comprehensive Analysis
        id: analysis
        shell: pwsh
        run: |
          Write-Host "ğŸ” Starting comprehensive failure analysis..." -ForegroundColor Cyan

          # Create issue state directory if it doesn't exist
          New-Item -ItemType Directory -Force -Path "$env:ISSUE_STATE_DIR" | Out-Null

          # Initialize analysis results
          $analysisResults = @{
            Timestamp = Get-Date -Format 'o'
            WorkflowContext = @{
              EventName = "${{ github.event_name }}"
              RunId = "${{ github.run_id }}"
              RunNumber = "${{ github.run_number }}"
              Actor = "${{ github.actor }}"
              Ref = "${{ github.ref }}"
              Sha = "${{ github.sha }}"
            }
            Failures = @{
              Tests = @()
              Syntax = @()
              CodeQuality = @()
              Security = @()
              Performance = @()
              Workflows = @()
            }
            IssueGroups = @()
          }

          if ("${{ github.event_name }}" -eq "workflow_run") {
            $analysisResults.WorkflowContext.TriggeredBy = @{
              WorkflowName = "${{ github.event.workflow_run.name }}"
              WorkflowId = "${{ github.event.workflow_run.id }}"
              Conclusion = "${{ github.event.workflow_run.conclusion }}"
              Status = "${{ github.event.workflow_run.status }}"
              HtmlUrl = "${{ github.event.workflow_run.html_url }}"
            }
          }

          Write-Host "ğŸ“‚ Searching for failure artifacts..." -ForegroundColor Yellow

          # 1. ANALYZE TEST FAILURES
          Write-Host "`nğŸ§ª Analyzing test failures..." -ForegroundColor Cyan
          $testReportFiles = Get-ChildItem -Path "./reports", "./artifacts" -Filter "TestReport*.json" -Recurse -ErrorAction SilentlyContinue

          foreach ($reportFile in $testReportFiles) {
            try {
              $report = Get-Content $reportFile.FullName -Raw | ConvertFrom-Json

              if ($report.TestResults.Details) {
                foreach ($result in $report.TestResults.Details) {
                  if ($result.Result -eq 'Failed') {
                    $analysisResults.Failures.Tests += @{
                      TestName = $result.Name ?? $result.ExpandedName ?? 'Unknown Test'
                      TestType = $report.TestType ?? 'Unknown'
                      ErrorMessage = if ($result.ErrorRecord) { $result.ErrorRecord.Exception.Message } elseif ($result.Error) { $result.Error } else { "Test failed" }
                      StackTrace = if ($result.ErrorRecord) { $result.ErrorRecord.ScriptStackTrace } else { $null }
                      File = if ($result.ScriptBlock) { $result.ScriptBlock.File } else { "Unknown" }
                      Line = if ($result.ScriptBlock) { $result.ScriptBlock.StartPosition.Line } else { 0 }
                      Duration = $result.Duration ?? 0
                      Timestamp = $report.Timestamp ?? (Get-Date -Format 'o')
                    }
                  }
                }
              }
            } catch {
              Write-Warning "Failed to parse test report: $($reportFile.Name) - $_"
            }
          }
          Write-Host "  Found $($analysisResults.Failures.Tests.Count) test failures" -ForegroundColor $(if ($analysisResults.Failures.Tests.Count -gt 0) { 'Red' } else { 'Green' })

          # 2. ANALYZE SYNTAX ERRORS
          Write-Host "`nğŸ“ Analyzing syntax errors..." -ForegroundColor Cyan
          $syntaxReportFiles = Get-ChildItem -Path "./reports", "./artifacts" -Filter "*syntax*.json" -Recurse -ErrorAction SilentlyContinue

          foreach ($reportFile in $syntaxReportFiles) {
            try {
              $report = Get-Content $reportFile.FullName -Raw | ConvertFrom-Json

              if ($report.Errors) {
                foreach ($error in $report.Errors) {
                  $analysisResults.Failures.Syntax += @{
                    File = $error.File ?? 'Unknown'
                    Line = $error.Line ?? 0
                    Message = $error.Message ?? 'Syntax error'
                    Severity = 'Error'
                    Category = 'Syntax'
                  }
                }
              }
            } catch {
              Write-Warning "Failed to parse syntax report: $($reportFile.Name) - $_"
            }
          }
          Write-Host "  Found $($analysisResults.Failures.Syntax.Count) syntax errors" -ForegroundColor $(if ($analysisResults.Failures.Syntax.Count -gt 0) { 'Red' } else { 'Green' })

          # 3. ANALYZE CODE QUALITY ISSUES
          Write-Host "`nâš ï¸  Analyzing code quality issues..." -ForegroundColor Cyan
          $qualityReportFiles = Get-ChildItem -Path "./reports", "./artifacts" -Filter "*psscriptanalyzer*.json" -Recurse -ErrorAction SilentlyContinue

          foreach ($reportFile in $qualityReportFiles) {
            try {
              $report = Get-Content $reportFile.FullName -Raw | ConvertFrom-Json

              if ($report.Results) {
                $groupedByFile = $report.Results | Group-Object -Property ScriptPath

                foreach ($group in $groupedByFile) {
                  $errors = @($group.Group | Where-Object { $_.Severity -eq 'Error' })
                  $warnings = @($group.Group | Where-Object { $_.Severity -eq 'Warning' })

                  if ($errors.Count -gt 0 -or $warnings.Count -gt 10) {
                    $analysisResults.Failures.CodeQuality += @{
                      File = $group.Name
                      ErrorCount = $errors.Count
                      WarningCount = $warnings.Count
                      Issues = @($group.Group | ForEach-Object {
                        @{
                          RuleName = $_.RuleName
                          Severity = $_.Severity
                          Message = $_.Message
                          Line = $_.Line
                        }
                      })
                    }
                  }
                }
              }
            } catch {
              Write-Warning "Failed to parse quality report: $($reportFile.Name) - $_"
            }
          }
          Write-Host "  Found $($analysisResults.Failures.CodeQuality.Count) files with quality issues" -ForegroundColor $(if ($analysisResults.Failures.CodeQuality.Count -gt 0) { 'Yellow' } else { 'Green' })

          # 4. ANALYZE SECURITY ISSUES
          Write-Host "`nğŸ”’ Analyzing security issues..." -ForegroundColor Cyan
          $securityReportFiles = Get-ChildItem -Path "./reports", "./artifacts" -Filter "*security*.json" -Recurse -ErrorAction SilentlyContinue

          foreach ($reportFile in $securityReportFiles) {
            try {
              $report = Get-Content $reportFile.FullName -Raw | ConvertFrom-Json

              if ($report.Vulnerabilities) {
                foreach ($vuln in $report.Vulnerabilities) {
                  $analysisResults.Failures.Security += @{
                    Type = $vuln.Type ?? 'Security Issue'
                    Severity = $vuln.Severity ?? 'Medium'
                    Description = $vuln.Description ?? 'Security vulnerability detected'
                    File = $vuln.File ?? 'Unknown'
                    Recommendation = $vuln.Recommendation ?? 'Review and remediate'
                  }
                }
              }
            } catch {
              Write-Warning "Failed to parse security report: $($reportFile.Name) - $_"
            }
          }
          Write-Host "  Found $($analysisResults.Failures.Security.Count) security issues" -ForegroundColor $(if ($analysisResults.Failures.Security.Count -gt 0) { 'Red' } else { 'Green' })

          # 5. ANALYZE WORKFLOW FAILURES
          Write-Host "`nğŸ”„ Analyzing workflow failures..." -ForegroundColor Cyan
          if ("${{ github.event.workflow_run.conclusion }}" -eq "failure") {
            $analysisResults.Failures.Workflows += @{
              WorkflowName = "${{ github.event.workflow_run.name }}"
              WorkflowId = "${{ github.event.workflow_run.id }}"
              Conclusion = "failure"
              HtmlUrl = "${{ github.event.workflow_run.html_url }}"
              Timestamp = Get-Date -Format 'o'
            }
          }
          Write-Host "  Found $($analysisResults.Failures.Workflows.Count) workflow failures" -ForegroundColor $(if ($analysisResults.Failures.Workflows.Count -gt 0) { 'Red' } else { 'Green' })

          # Calculate total failures
          $totalFailures = $analysisResults.Failures.Tests.Count +
                          $analysisResults.Failures.Syntax.Count +
                          $analysisResults.Failures.CodeQuality.Count +
                          $analysisResults.Failures.Security.Count +
                          $analysisResults.Failures.Workflows.Count

          Write-Host "`nğŸ“Š Analysis Summary:" -ForegroundColor Green
          Write-Host "  Total Failures: $totalFailures" -ForegroundColor White
          Write-Host "    â€¢ Test Failures: $($analysisResults.Failures.Tests.Count)" -ForegroundColor White
          Write-Host "    â€¢ Syntax Errors: $($analysisResults.Failures.Syntax.Count)" -ForegroundColor White
          Write-Host "    â€¢ Code Quality: $($analysisResults.Failures.CodeQuality.Count)" -ForegroundColor White
          Write-Host "    â€¢ Security Issues: $($analysisResults.Failures.Security.Count)" -ForegroundColor White
          Write-Host "    â€¢ Workflow Failures: $($analysisResults.Failures.Workflows.Count)" -ForegroundColor White

          # Save analysis results
          $analysisResults | ConvertTo-Json -Depth 20 | Out-File -FilePath "./comprehensive-failure-analysis.json"

          # Set outputs
          "has-failures=$($totalFailures -gt 0)" >> $env:GITHUB_OUTPUT
          "analysis-artifact=comprehensive-failure-analysis" >> $env:GITHUB_OUTPUT

          Write-Host "`nâœ… Comprehensive analysis complete!" -ForegroundColor Green

      - name: ğŸ“¤ Upload Analysis Results
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-failure-analysis
          path: comprehensive-failure-analysis.json
          retention-days: 30

  intelligent-issue-grouping:
    name: ğŸ§  Intelligent Issue Grouping & Deduplication
    runs-on: ubuntu-latest
    needs: comprehensive-failure-analysis
    if: needs.comprehensive-failure-analysis.outputs.has-failures == 'true'

    outputs:
      issue-count: ${{ steps.grouping.outputs.issue-count }}

    steps:
      - name: ğŸ“¥ Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ“Š Download Analysis Results
        uses: actions/download-artifact@v4
        with:
          name: comprehensive-failure-analysis
          path: ./

      - name: ğŸ“¥ Download Issue State
        uses: actions/download-artifact@v4
        with:
          name: issue-state-db
          path: ${{ env.ISSUE_STATE_DIR }}
        continue-on-error: true

      - name: ğŸ§  Intelligent Grouping
        id: grouping
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const crypto = require('crypto');

            // Load analysis results
            const analysis = JSON.parse(fs.readFileSync('./comprehensive-failure-analysis.json', 'utf8'));
            console.log('ğŸ“Š Loaded analysis with', Object.keys(analysis.Failures).length, 'failure categories');

            // Load existing issues to check for duplicates
            const { data: existingIssues } = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              labels: 'automated-issue',
              state: 'open',
              per_page: 100
            });

            console.log(`Found ${existingIssues.length} existing automated issues`);

            // Helper: Create fingerprint for deduplication with enhanced normalization
            function createFingerprint(failure) {
              // Normalize file paths - remove absolute paths, keep only relative structure
              const normalizeFile = (filePath) => {
                if (!filePath) return 'unknown';
                return filePath
                  .replace(/\\/g, '/')  // Normalize path separators
                  .replace(/^.*?(domains|tests|automation-scripts|infrastructure)/i, '$1')  // Remove prefix before key directories
                  .toLowerCase()
                  .trim();
              };

              // Normalize error messages - remove volatile data that changes between runs
              const normalizeError = (errorMsg) => {
                if (!errorMsg) return 'unknown';
                return errorMsg
                  .toLowerCase()
                  // Replace specific patterns FIRST before general number replacement
                  .replace(/\b[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\b/g, 'GUID')  // Replace GUIDs (lowercase only after toLowerCase)
                  .replace(/\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}(\.\d+)?Z?/g, 'TIMESTAMP')  // Replace ISO timestamps
                  .replace(/\d{4}-\d{2}-\d{2}/g, 'DATE')  // Replace dates
                  .replace(/\b[0-9a-f]{32,}\b/g, 'HASH')  // Replace long hex strings (hashes, lowercase only after toLowerCase)
                  // THEN replace general patterns
                  .replace(/line \d+/gi, 'line N')  // Normalize line numbers
                  .replace(/at \d+:\d+/g, 'at N:N')  // Normalize position references
                  .replace(/\d+/g, 'N')  // Replace all remaining numbers with 'N'
                  .replace(/\s+/g, ' ')  // Normalize whitespace
                  .trim();
              };

              // Normalize test names - keep the test name but remove parameters
              const normalizeTestName = (testName) => {
                if (!testName) return 'unknown';
                return testName
                  .replace(/\s*\[.*?\]\s*/g, '')  // Remove parameterized test data in brackets
                  .replace(/\s+\d+\s+/g, ' ')  // Remove numbers between words
                  .toLowerCase()
                  .trim();
              };

              // Build stable fingerprint from normalized data
              const fingerprintData = {
                type: failure.Type || failure.TestType || 'unknown',
                file: normalizeFile(failure.File),
                error: normalizeError(failure.ErrorMessage || failure.Message),
                category: failure.Category || failure.RuleName || 'general',
                testName: failure.TestName ? normalizeTestName(failure.TestName) : undefined
              };

              // Remove undefined values for stable hashing
              Object.keys(fingerprintData).forEach(key => {
                if (fingerprintData[key] === undefined) {
                  delete fingerprintData[key];
                }
              });

              const normalizedData = JSON.stringify(fingerprintData, Object.keys(fingerprintData).sort());
              const fingerprint = crypto.createHash('sha256').update(normalizedData).digest('hex').substring(0, 16);

              // Log fingerprint generation for debugging
              console.log(`  Generated fingerprint ${fingerprint} for:`, {
                file: fingerprintData.file,
                type: fingerprintData.type,
                category: fingerprintData.category
              });

              return fingerprint;
            }

            // Helper: Determine agent based on file and error type
            function determineAgent(failure) {
              const file = (failure.File || '').toLowerCase();
              const error = (failure.ErrorMessage || failure.Message || '').toLowerCase();

              // Infrastructure issues
              if (file.includes('infrastructure') || file.includes('vm') || file.includes('network') || file.includes('hyperv')) {
                return { agent: 'maya', name: 'Maya Infrastructure', mention: '@maya' };
              }

              // Security issues
              if (file.includes('security') || file.includes('certificate') || file.includes('credential') || error.includes('security')) {
                return { agent: 'sarah', name: 'Sarah Security', mention: '@sarah' };
              }

              // Test infrastructure issues
              if (file.includes('tests/') || file.includes('.Tests.ps1') || error.includes('pester')) {
                return { agent: 'jessica', name: 'Jessica Testing', mention: '@jessica' };
              }

              // UI/UX issues
              if (file.includes('experience/') || file.includes('ui') || file.includes('menu') || file.includes('wizard')) {
                return { agent: 'emma', name: 'Emma Frontend', mention: '@emma' };
              }

              // Backend/Module issues
              if (file.includes('.psm1') || file.includes('api') || file.includes('backend')) {
                return { agent: 'marcus', name: 'Marcus Backend', mention: '@marcus' };
              }

              // Documentation issues
              if (file.endsWith('.md') || file.includes('docs/')) {
                return { agent: 'olivia', name: 'Olivia Documentation', mention: '@olivia' };
              }

              // Default to PowerShell expert
              return { agent: 'rachel', name: 'Rachel PowerShell', mention: '@rachel' };
            }

            // Group failures intelligently
            const issueGroups = [];
            const processedFingerprints = new Set();

            // Process each failure type
            for (const [category, failures] of Object.entries(analysis.Failures)) {
              if (!failures || failures.length === 0) continue;

              console.log(`\nProcessing ${failures.length} ${category} failures...`);

              for (const failure of failures) {
                const fingerprint = createFingerprint(failure);

                // Check if already processed in this run
                if (processedFingerprints.has(fingerprint)) {
                  console.log(`  Skipping duplicate: ${fingerprint}`);
                  continue;
                }

                // Check if issue already exists
                const existingIssue = existingIssues.find(i =>
                  i.body && i.body.includes(`<!-- fingerprint:${fingerprint} -->`)
                );

                processedFingerprints.add(fingerprint);

                // Determine assigned agent
                const agent = determineAgent(failure);

                // Create issue group (includes both new and existing issues for updates)
                issueGroups.push({
                  fingerprint,
                  category,
                  failure,
                  agent,
                  priority: category === 'Security' ? 'p0' : category === 'Syntax' ? 'p1' : 'p2',
                  existingIssueNumber: existingIssue ? existingIssue.number : null,
                  existingIssueTitle: existingIssue ? existingIssue.title : null
                });

                if (existingIssue) {
                  console.log(`  Will update existing issue #${existingIssue.number} for fingerprint: ${fingerprint}`);
                } else {
                  console.log(`  Will create new issue for fingerprint: ${fingerprint}`);
                }
              }
            }

            console.log(`\nâœ… Created ${issueGroups.length} unique issue groups`);

            // Save grouped issues
            fs.writeFileSync('./issue-groups.json', JSON.stringify({ issueGroups, analysis }, null, 2));

            core.setOutput('issue-count', issueGroups.length);

            return issueGroups.length;

      - name: ğŸ“¤ Upload Issue Groups
        uses: actions/upload-artifact@v4
        with:
          name: issue-groups
          path: issue-groups.json
          retention-days: 30

  create-intelligent-issues:
    name: ğŸ“ Create Intelligent Issues
    runs-on: ubuntu-latest
    needs: [comprehensive-failure-analysis, intelligent-issue-grouping]
    if: |
      needs.intelligent-issue-grouping.outputs.issue-count > 0 &&
      github.event.inputs.dry_run != 'true'

    steps:
      - name: ğŸ“¥ Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ“Š Download Issue Groups
        uses: actions/download-artifact@v4
        with:
          name: issue-groups
          path: ./

      - name: ğŸ“ Create Issues with Agent Assignment
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            // Load issue groups
            const data = JSON.parse(fs.readFileSync('./issue-groups.json', 'utf8'));
            const { issueGroups, analysis } = data;

            console.log(`ğŸ“ Creating ${issueGroups.length} intelligent issues...`);

            let createdCount = 0;
            let updatedCount = 0;

            for (const group of issueGroups) {
              const { fingerprint, category, failure, agent, priority, existingIssueNumber, existingIssueTitle } = group;

              // Build descriptive issue title with context
              let title = '';
              if (category === 'Tests') {
                const fileName = failure.File ? failure.File.split('/').pop() : 'Unknown';
                const testName = failure.TestName || 'Unknown Test';
                // Include file and test name for better context
                title = `ğŸ§ª Test Failure: ${testName} in ${fileName}`;
              } else if (category === 'Syntax') {
                const fileName = failure.File ? failure.File.split('/').pop() : 'Unknown';
                // Include brief error context (using slice for Unicode safety)
                const errorSnippet = (failure.Message || failure.ErrorMessage || '').split('\n')[0].slice(0, 80);
                title = `ğŸ“ Syntax Error: ${fileName} - ${errorSnippet || 'Parse error'}`;
              } else if (category === 'CodeQuality') {
                const fileName = failure.File ? failure.File.split('/').pop() : 'Unknown';
                const errorCount = failure.ErrorCount || 0;
                const warningCount = failure.WarningCount || 0;
                // Include counts for better understanding
                title = `âš ï¸ Code Quality: ${fileName} (${errorCount} errors, ${warningCount} warnings)`;
              } else if (category === 'Security') {
                const severity = failure.Severity || 'Unknown';
                const type = failure.Type || 'Security Issue';
                // Include severity for prioritization
                title = `ğŸ”’ Security [${severity}]: ${type}`;
              } else if (category === 'Workflows') {
                const workflowName = failure.WorkflowName || 'Unknown Workflow';
                const conclusion = failure.Conclusion || 'failed';
                // Include workflow name and status
                title = `ğŸ”„ Workflow ${conclusion}: ${workflowName}`;
              } else {
                // Fallback for unknown categories
                title = `âŒ ${category} Failure: ${failure.File ? failure.File.split('/').pop() : 'Unknown'}`;
              }

              // Build issue body with rich context
              const workflowContext = analysis.WorkflowContext.TriggeredBy
                ? `- **Workflow:** [${analysis.WorkflowContext.TriggeredBy.WorkflowName}](${analysis.WorkflowContext.TriggeredBy.HtmlUrl})
            - **Run ID:** ${analysis.WorkflowContext.TriggeredBy.WorkflowId}
            - **Status:** ${analysis.WorkflowContext.TriggeredBy.Conclusion}`
                : `- **Manual Analysis:** Scheduled analysis`;

              const body = `## ${category} Failure Detected

            **Category:** ${category}
            **Priority:** ${priority}
            **Detected:** ${analysis.Timestamp}
            **File:** \`${failure.File || 'N/A'}\`
            ${failure.Line ? `**Line:** ${failure.Line}` : ''}

            ### Error Details

            ${failure.ErrorMessage || failure.Message || failure.Description || 'See details below'}

            ${failure.StackTrace ? `\`\`\`
            ${failure.StackTrace}
            \`\`\`` : ''}

            ### ğŸ¤– AI Agent Assignment

            ${agent.mention} This issue has been automatically assigned to you based on the failure category and affected files.

            **Agent:** ${agent.name}
            **Expertise:** ${agent.agent}

            #### Recommended Actions:

            1. **Analyze** the failure details and identify the root cause
            2. **Review** related code in \`${failure.File || 'affected files'}\`
            3. **Fix** the underlying issue
            4. **Test** to verify the fix works
            5. **Submit** a PR that references this issue with \`Fixes #ISSUE_NUMBER\`

            ${category === 'Security' ? 'âš ï¸ **Security Issue:** Please prioritize this fix for security reasons.' : ''}

            ### Workflow Context

            ${workflowContext}

            ---
            *This issue was automatically created by the Phase 2 Intelligent Issue Creation System*
            <!-- fingerprint:${fingerprint} -->`;

              try {
                const labels = ['automated-issue', category.toLowerCase(), priority];

                // Add agent-specific label
                labels.push(`agent-${agent.agent}`);

                if (existingIssueNumber) {
                  // Update existing issue with latest information
                  console.log(`ğŸ”„ Updating existing issue #${existingIssueNumber}: ${title}`);

                  // Add a comment with the latest failure information
                  const updateComment = `## ğŸ”„ Issue Still Occurring (Updated)

            **Last Detected:** ${analysis.Timestamp}
            **Status:** This issue is still occurring in recent workflow runs.

            ### Latest Failure Details

            **File:** \`${failure.File || 'N/A'}\`
            ${failure.Line ? `**Line:** ${failure.Line}` : ''}

            ${failure.ErrorMessage || failure.Message || failure.Description || 'See details below'}

            ${failure.StackTrace ? `\`\`\`
            ${failure.StackTrace}
            \`\`\`` : ''}

            ### Workflow Context

            ${workflowContext}

            ---
            *This issue remains open and has been updated with the latest failure information.*
            <!-- updated:${new Date().toISOString()} -->`;

                  await github.rest.issues.createComment({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: existingIssueNumber,
                    body: updateComment
                  });

                  // Helper to normalize titles by trimming and collapsing whitespace
                  const normalizeTitle = (str) => str.trim().replace(/\s+/g, ' ');

                  // Update title if it's different (more descriptive now)
                  if (normalizeTitle(existingIssueTitle) !== normalizeTitle(title)) {
                    await github.rest.issues.update({
                      owner: context.repo.owner,
                      repo: context.repo.repo,
                      issue_number: existingIssueNumber,
                      title: title
                    });
                    console.log(`  âœï¸ Updated title to: ${title}`);
                  }

                  // Ensure labels are up to date
                  await github.rest.issues.addLabels({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: existingIssueNumber,
                    labels: labels
                  });

                  console.log(`âœ… Updated issue #${existingIssueNumber}`);
                  updatedCount++;

                } else {
                  // Create new issue
                  const newIssue = await github.rest.issues.create({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    title,
                    body,
                    labels
                  });

                  console.log(`âœ… Created issue #${newIssue.data.number}: ${title}`);
                  createdCount++;
                }

              } catch (error) {
                console.error(`âŒ Failed to ${existingIssueNumber ? 'update' : 'create'} issue: ${error.message}`);
              }
            }

            console.log(`\nâœ… Issue Creation Summary:`);
            console.log(`   Created: ${createdCount} new issues`);
            console.log(`   Updated: ${updatedCount} existing issues`);
            console.log(`   Total processed: ${createdCount + updatedCount} issues`);

      - name: ğŸ“Š Update Issue State Database
        shell: pwsh
        run: |
          Write-Host "ğŸ“Š Updating issue state database..." -ForegroundColor Cyan

          $issueStateFile = "$env:ISSUE_STATE_DIR/issue-fingerprints.json"

          # Load existing state
          $issueState = if (Test-Path $issueStateFile) {
            Get-Content $issueStateFile -Raw | ConvertFrom-Json
          } else {
            @{ fingerprints = @(); lastUpdated = $null }
          }

          # Load created issues
          $issueGroups = Get-Content "./issue-groups.json" -Raw | ConvertFrom-Json

          # Add new fingerprints
          foreach ($group in $issueGroups.issueGroups) {
            if ($group.fingerprint -notin $issueState.fingerprints) {
              $issueState.fingerprints += $group.fingerprint
            }
          }

          $issueState.lastUpdated = Get-Date -Format 'o'
          $issueState.totalTracked = $issueState.fingerprints.Count

          # Save updated state
          New-Item -ItemType Directory -Force -Path "$env:ISSUE_STATE_DIR" | Out-Null
          $issueState | ConvertTo-Json -Depth 10 | Out-File -FilePath $issueStateFile

          Write-Host "âœ… Updated issue state database with $($issueState.fingerprints.Count) fingerprints" -ForegroundColor Green

      - name: ğŸ“¤ Upload Issue State Database
        uses: actions/upload-artifact@v4
        with:
          name: issue-state-db
          path: ${{ env.ISSUE_STATE_DIR }}
          retention-days: 90

  dry-run-preview:
    name: ğŸ§ª Dry Run Preview
    runs-on: ubuntu-latest
    needs: [comprehensive-failure-analysis, intelligent-issue-grouping]
    if: |
      github.event.inputs.dry_run == 'true' &&
      needs.intelligent-issue-grouping.outputs.issue-count > 0

    steps:
      - name: ğŸ“Š Download Issue Groups
        uses: actions/download-artifact@v4
        with:
          name: issue-groups
          path: ./

      - name: ğŸ“‹ Preview Issues
        shell: pwsh
        run: |
          Write-Host "ğŸ§ª DRY RUN MODE - Previewing issues that would be created" -ForegroundColor Yellow
          Write-Host "============================================================" -ForegroundColor Yellow
          Write-Host ""

          $data = Get-Content "./issue-groups.json" -Raw | ConvertFrom-Json

          Write-Host "ğŸ“Š Summary:" -ForegroundColor Cyan
          Write-Host "  Total Issues to Create: $($data.issueGroups.Count)" -ForegroundColor White
          Write-Host ""

          foreach ($group in $data.issueGroups) {
            Write-Host "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”" -ForegroundColor DarkGray
            Write-Host "  Category: $($group.category)" -ForegroundColor Yellow
            Write-Host "  Priority: $($group.priority)" -ForegroundColor Yellow
            Write-Host "  Agent: $($group.agent.name)" -ForegroundColor Cyan
            Write-Host "  File: $($group.failure.File)" -ForegroundColor White
            Write-Host "  Fingerprint: $($group.fingerprint)" -ForegroundColor DarkGray
            Write-Host ""
          }

          Write-Host "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”" -ForegroundColor DarkGray
          Write-Host ""
          Write-Host "ğŸ’¡ Run without dry_run to create these issues" -ForegroundColor Blue
