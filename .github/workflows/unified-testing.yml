---
name: ğŸ¯ Unified Testing Orchestration

# Simplified workflow using playbook orchestration
on:
  push:
    branches: [main, develop, dev]
    paths:
      - 'domains/**'
      - 'automation-scripts/**'
      - 'tests/**'
      - '**.ps1'
      - '**.psm1'
  pull_request:
    branches: [main, develop, dev]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC
  workflow_dispatch:
    inputs:
      profile:
        description: 'Test profile to run'
        type: choice
        options:
          - quick
          - standard
          - full
          - ci
        default: 'standard'

permissions:
  contents: write
  checks: write
  pull-requests: write
  pages: write

concurrency:
  group: unified-tests-${{ github.ref }}
  cancel-in-progress: true

env:
  AITHERZERO_CI: true
  AITHERZERO_NONINTERACTIVE: true
  GH_TOKEN: ${{ github.token }}

jobs:
  orchestrated-tests:
    name: ğŸ¯ Orchestrated Testing (${{ github.event.inputs.profile || 'standard' }})
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
      
      - name: ğŸŸ¢ Setup Node.js 18.x
        uses: actions/setup-node@v4
        with:
          node-version: 18
      
      - name: ğŸ”§ Bootstrap Environment
        shell: pwsh
        timeout-minutes: 5
        run: |
          Write-Host "ğŸš€ Bootstrapping AitherZero..." -ForegroundColor Cyan
          ./bootstrap.ps1 -Mode New -InstallProfile Minimal
      
      - name: ğŸ¼ Run Test Orchestration
        shell: pwsh
        timeout-minutes: 20
        run: |
          $profile = "${{ github.event.inputs.profile }}"
          if (-not $profile) { $profile = "ci" }
          
          Write-Host "ğŸ¼ Starting orchestrated testing with profile: $profile" -ForegroundColor Cyan
          Write-Host "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•" -ForegroundColor Cyan
          
          ./Start-AitherZero.ps1 -Mode Orchestrate -Playbook "test-orchestrated" -Profile $profile
          
          $exitCode = $LASTEXITCODE
          Write-Host "`nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•" -ForegroundColor Cyan
          Write-Host "ğŸ¯ Orchestration completed with exit code: $exitCode" -ForegroundColor $(if ($exitCode -eq 0) { 'Green' } else { 'Red' })
          
          exit $exitCode
      
      - name: ğŸ“‹ Validate Documentation Coverage
        if: always()
        shell: pwsh
        continue-on-error: true
        run: |
          Write-Host "ğŸ“š Validating directory documentation..." -ForegroundColor Cyan
          ./automation-scripts/0961_Validate-DirectoryDocumentation.ps1 -CheckMissing
      
      - name: ğŸ“… Track Documentation Freshness
        if: always()
        shell: pwsh
        continue-on-error: true
        run: |
          Write-Host "â° Tracking documentation updates..." -ForegroundColor Cyan
          ./automation-scripts/0960_Track-DocumentationFreshness.ps1 -ReportOnly
      
      - name: ğŸ“Š Generate Dashboard
        if: always()
        shell: pwsh
        continue-on-error: true
        run: |
          Write-Host "ğŸ“Š Generating comprehensive dashboard..." -ForegroundColor Cyan
          ./automation-scripts/0512_Generate-Dashboard.ps1 -Format All
      
      - name: ğŸ“ˆ Create Summary
        if: always()
        shell: pwsh
        run: |
          # Find latest report
          $reportJson = Get-ChildItem "./reports" -Filter "dashboard.json" -ErrorAction SilentlyContinue | 
            Select-Object -First 1
          
          if ($reportJson) {
            $report = Get-Content $reportJson.FullName | ConvertFrom-Json
            
            # Build GitHub step summary
            $summary = @"
          # ğŸ¯ Test Orchestration Results
          
          **Profile:** ${{ github.event.inputs.profile || 'ci' }}  
          **Status:** $(if ($report.Summary.FailedTests -eq 0) { 'âœ… PASSED' } else { 'âŒ FAILED' })  
          **Generated:** $(Get-Date -Format 'yyyy-MM-dd HH:mm:ss')
          
          ## ğŸ“Š Test Summary
          
          | Metric | Value |
          |--------|-------|
          | Total Tests | $($report.Summary.TotalTests) |
          | âœ… Passed | $($report.Summary.PassedTests) |
          | âŒ Failed | $($report.Summary.FailedTests) |
          | â­ï¸ Skipped | $($report.Summary.SkippedTests) |
          
          ## ğŸ› Quality Issues
          
          | Severity | Count |
          |----------|-------|
          | ğŸ”´ Critical | $($report.Summary.CriticalIssues) |
          | ğŸŸ  High | $($report.Summary.HighIssues) |
          | ğŸŸ¡ Medium | $($report.Summary.MediumIssues) |
          | ğŸ”µ Low | $($report.Summary.LowIssues) |
          
          ## ğŸ“„ Reports
          
          - [Dashboard](./reports/dashboard.html)
          - [Detailed Report](./reports/test-summary.md)
          
          "@
            
            $summary | Out-File -FilePath $env:GITHUB_STEP_SUMMARY -Encoding UTF8
          } else {
            Write-Host "âš ï¸  No dashboard found - tests may have failed early" -ForegroundColor Yellow
            @"
          # ğŸ¯ Test Orchestration Results
          
          âš ï¸ **No dashboard generated** - tests may have failed during execution.
          Check the workflow logs for details.
          "@ | Out-File -FilePath $env:GITHUB_STEP_SUMMARY -Encoding UTF8
          }
      
      - name: ğŸ“¤ Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            tests/results/**/*.xml
            tests/results/**/*.json
          retention-days: 30
      
      - name: ğŸ“¤ Upload Reports & Dashboard
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-reports-dashboard
          path: |
            reports/**/*.html
            reports/**/*.json
            reports/**/*.md
          retention-days: 30
      
      - name: ğŸ“Š Publish Test Results
        if: always()
        uses: EnricoMi/publish-unit-test-result-action@v2
        with:
          files: 'tests/results/**/{UnitTests,IntegrationTests}-*.xml'
          check_name: 'Test Results'
          comment_mode: always
        continue-on-error: true
      
      - name: ğŸ’¬ Comment on PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // Try to read dashboard summary
            let summary = '## ğŸ¯ Test Orchestration Results\n\n';
            
            try {
              const dashboardPath = './reports/dashboard.json';
              if (fs.existsSync(dashboardPath)) {
                const dashboard = JSON.parse(fs.readFileSync(dashboardPath, 'utf8'));
                const passRate = dashboard.Summary.TotalTests > 0 
                  ? Math.round((dashboard.Summary.PassedTests / dashboard.Summary.TotalTests) * 100)
                  : 0;
                
                const status = dashboard.Summary.FailedTests === 0 ? 'âœ… PASSED' : 'âŒ FAILED';
                
                summary += `**Profile:** ${{ github.event.inputs.profile || 'ci' }}\n`;
                summary += `**Status:** ${status}\n`;
                summary += `**Pass Rate:** ${passRate}%\n\n`;
                summary += `| Tests | Issues |\n`;
                summary += `|-------|--------|\n`;
                summary += `| Total: ${dashboard.Summary.TotalTests} | Total: ${dashboard.Summary.TotalIssues} |\n`;
                summary += `| âœ… ${dashboard.Summary.PassedTests} | ğŸ”´ ${dashboard.Summary.CriticalIssues} critical |\n`;
                summary += `| âŒ ${dashboard.Summary.FailedTests} | ğŸŸ  ${dashboard.Summary.HighIssues} high |\n`;
                summary += `| â­ï¸ ${dashboard.Summary.SkippedTests} | ğŸŸ¡ ${dashboard.Summary.MediumIssues} medium |\n\n`;
                summary += `ğŸ“Š [View Full Dashboard](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})\n`;
              } else {
                summary += 'âš ï¸ Dashboard not generated - check workflow logs for details.\n';
              }
            } catch (error) {
              summary += `âš ï¸ Error reading dashboard: ${error.message}\n`;
            }
            
            // Post comment
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: summary
            });

  publish-dashboard:
    name: ğŸ“Š Publish Dashboard to GitHub Pages
    runs-on: ubuntu-latest
    needs: orchestrated-tests
    if: always() && github.ref == 'refs/heads/main'
    
    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
      
      - name: ğŸ“Š Download Reports
        uses: actions/download-artifact@v4
        with:
          name: test-reports-dashboard
          path: ./reports
        continue-on-error: true
      
      - name: ğŸ”§ Setup Pages
        uses: actions/configure-pages@v5
      
      - name: ğŸ—ï¸ Build with Jekyll
        uses: actions/jekyll-build-pages@v1
        with:
          source: ./reports
          destination: ./_site
      
      - name: ğŸ“¤ Upload Pages Artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./_site
      
      - name: ğŸš€ Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
        continue-on-error: true
      
      - name: ğŸ“‹ Report Deployment
        if: steps.deployment.outcome == 'success'
        run: |
          echo "âœ… Dashboard published to GitHub Pages!"
          echo "ğŸ”— URL: ${{ steps.deployment.outputs.page_url }}"
