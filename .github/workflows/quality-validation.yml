---
name: Quality Validation

# Run quality checks on new features and components
on:
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]
    # Run on all PRs - removed overly restrictive path filters
  workflow_dispatch:
    inputs:
      path:
        description: 'Path to validate (file or directory)'
        required: false
        default: './domains'
      recursive:
        description: 'Validate recursively'
        type: boolean
        default: true

permissions:
  contents: read
  pull-requests: write
  checks: write
  issues: write

concurrency:
  group: quality-validation-${{ github.event.pull_request.number || github.run_id }}
  cancel-in-progress: true

env:
  AITHERZERO_CI: true
  AITHERZERO_NONINTERACTIVE: true

jobs:
  quality-validation:
    name: Quality Validation
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: üì• Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 2  # Need base for diff

      - name: üîß Bootstrap Environment
        shell: pwsh
        run: |
          Write-Host "üöÄ Bootstrapping AitherZero environment..." -ForegroundColor Cyan
          ./bootstrap.ps1 -Mode New -NonInteractive -InstallProfile Minimal

      - name: üíæ Cache PowerShell Modules
        uses: actions/cache@v4
        with:
          path: ~/.local/share/powershell/Modules
          key: ${{ runner.os }}-powershell-modules-pester-psscriptanalyzer-v1
          restore-keys: |
            ${{ runner.os }}-powershell-modules-

      - name: üì¶ Install Testing Dependencies
        shell: pwsh
        run: |
          # Install PSScriptAnalyzer if not cached
          if (-not (Get-Module -ListAvailable PSScriptAnalyzer)) {
            Write-Host "Installing PSScriptAnalyzer..." -ForegroundColor Yellow
            Install-Module -Name PSScriptAnalyzer -Force -SkipPublisherCheck -Scope CurrentUser
          } else {
            Write-Host "PSScriptAnalyzer already installed" -ForegroundColor Green
          }

      - name: üîç Detect Changed PowerShell Files
        id: changes
        shell: pwsh
        run: |
          Write-Host "üîç Detecting changed PowerShell files..." -ForegroundColor Cyan
          
          # Get changed files from git diff
          $changedFiles = @()
          
          if ("${{ github.event_name }}" -eq "pull_request") {
            # For PRs, compare with base branch (no origin/ prefix needed in GitHub Actions)
            $gitDiff = git diff --name-only ${{ github.event.pull_request.base.sha }}..HEAD
            $changedFiles = $gitDiff | Where-Object {
              $_ -match '\.(ps1|psm1|psd1)$' -and
              $_ -notmatch '^(tests|legacy-to-migrate|\.archive)/'
            }
          } else {
            # For workflow_dispatch, use input path
            $path = "${{ github.event.inputs.path || './domains' }}"
            $recursive = "${{ github.event.inputs.recursive }}" -eq "true"
            
            $params = @{
              Path = $path
              Include = '*.ps1', '*.psm1', '*.psd1'
              File = $true
            }
            
            if ($recursive) {
              $params.Recurse = $true
            }
            
            $changedFiles = Get-ChildItem @params | Select-Object -ExpandProperty FullName
          }
          
          if (-not $changedFiles) {
            Write-Host "‚ö†Ô∏è No PowerShell files to validate" -ForegroundColor Yellow
            echo "has-files=false" >> $env:GITHUB_OUTPUT
            exit 0
          }
          
          Write-Host "Found $($changedFiles.Count) PowerShell file(s) to validate:" -ForegroundColor Green
          $changedFiles | ForEach-Object { Write-Host "  - $_" -ForegroundColor White }
          
          # Save files to output
          $filesJson = $changedFiles | ConvertTo-Json -Compress
          echo "has-files=true" >> $env:GITHUB_OUTPUT
          echo "files=$filesJson" >> $env:GITHUB_OUTPUT
          echo "count=$($changedFiles.Count)" >> $env:GITHUB_OUTPUT

      - name: üîç Run Quality Validation
        if: steps.changes.outputs.has-files == 'true'
        id: validation
        shell: pwsh
        run: |
          Write-Host "üîç Running quality validation..." -ForegroundColor Cyan
          
          # Import AitherZero module
          Import-Module ./AitherZero.psd1 -Force
          
          # Get changed files
          $filesJson = '${{ steps.changes.outputs.files }}'
          $files = $filesJson | ConvertFrom-Json
          
          # Run validation on each file
          $allResults = @()
          $exitCode = 0
          
          foreach ($file in $files) {
            Write-Host "`nValidating: $file" -ForegroundColor Yellow
            
            try {
              # Run quality validation
              $result = & ./automation-scripts/0420_Validate-ComponentQuality.ps1 `
                -Path $file `
                -Format JSON `
                -MinimumScore 70 `
                -ErrorAction Stop
              
              if ($LASTEXITCODE -ne 0) {
                $exitCode = 1
              }
              
            } catch {
              Write-Host "‚ùå Validation failed for $file : $_" -ForegroundColor Red
              $exitCode = 1
            }
          }
          
          # Set output
          echo "exit-code=$exitCode" >> $env:GITHUB_OUTPUT
          
          if ($exitCode -ne 0) {
            Write-Host "`n‚ùå Quality validation failed for one or more files" -ForegroundColor Red
          } else {
            Write-Host "`n‚úÖ Quality validation passed for all files" -ForegroundColor Green
          }

      - name: üìä Upload Quality Reports
        if: always() && steps.changes.outputs.has-files == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: quality-reports
          path: |
            reports/quality/*.json
            reports/quality/*.html
            reports/quality/*.txt
          retention-days: 30

      - name: üí¨ Comment PR with Results
        if: always() && github.event_name == 'pull_request' && steps.changes.outputs.has-files == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // Read quality reports
            const reportsDir = './reports/quality';
            const prNumber = context.payload.pull_request.number;
            const runUrl = `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            const repoUrl = `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}`;
            
            let reportContent = '## üîç Quality Validation Report\n\n';
            
            try {
              if (fs.existsSync(reportsDir)) {
                const summaryFiles = fs.readdirSync(reportsDir)
                  .filter(f => f.endsWith('-summary.json'));
                
                if (summaryFiles.length > 0) {
                  const summaryPath = path.join(reportsDir, summaryFiles[0]);
                  const summary = JSON.parse(fs.readFileSync(summaryPath, 'utf8'));
                  
                  // Status Badge
                  const statusIcon = summary.OverallStatus === 'Passed' ? '‚úÖ' : 
                                    summary.OverallStatus === 'Warning' ? '‚ö†Ô∏è' : '‚ùå';
                  const scoreColor = summary.AverageScore >= 90 ? 'üü¢' : 
                                    summary.AverageScore >= 70 ? 'üü°' : 'üî¥';
                  
                  reportContent += `### ${statusIcon} Overall Status: **${summary.OverallStatus}**\n\n`;
                  reportContent += `| Metric | Value |\n`;
                  reportContent += `|--------|-------|\n`;
                  reportContent += `| üìä **Average Score** | ${scoreColor} **${summary.AverageScore}%** |\n`;
                  reportContent += `| üìù **Files Validated** | ${summary.FilesValidated || 0} |\n`;
                  reportContent += `| ‚úÖ **Passed** | ${summary.Passed || 0} |\n`;
                  reportContent += `| ‚ö†Ô∏è **Warnings** | ${summary.Warnings || 0} |\n`;
                  reportContent += `| ‚ùå **Failed** | ${summary.Failed || 0} |\n\n`;
                  
                  // File-by-file breakdown with detailed findings
                  if (summary.Files && Array.isArray(summary.Files) && summary.Files.length > 0) {
                    reportContent += `### üìã Detailed File Analysis\n\n`;
                    
                    for (const fileInfo of summary.Files) {
                      const fileName = path.basename(fileInfo.FilePath);
                      const icon = fileInfo.Status === 'Passed' ? '‚úÖ' : 
                                  fileInfo.Status === 'Warning' ? '‚ö†Ô∏è' : '‚ùå';
                      
                      reportContent += `<details>\n`;
                      reportContent += `<summary>${icon} <strong>${fileName}</strong> - Score: ${fileInfo.Score}% (${fileInfo.Status})</summary>\n\n`;
                      
                      // Try to find detailed report for this file
                      // Use more precise filename matching to avoid false positives
                      const baseName = fileName.replace(/\.(ps1|psm1|psd1)$/, '');
                      const detailedReportFiles = fs.readdirSync(reportsDir)
                        .filter(f => {
                          // Match files that contain the base name followed by .json (not summary)
                          // Use word boundary-like matching to avoid substring matches
                          const namePattern = new RegExp(`-${baseName.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')}\\.json$`, 'i');
                          return namePattern.test(f) && !f.includes('summary');
                        });
                      
                      if (detailedReportFiles.length > 0) {
                        try {
                          const detailedPath = path.join(reportsDir, detailedReportFiles[0]);
                          const detailed = JSON.parse(fs.readFileSync(detailedPath, 'utf8'));
                          
                          if (detailed.Checks && detailed.Checks.length > 0) {
                            reportContent += `#### Quality Checks\n\n`;
                            reportContent += `| Check | Status | Score | Findings |\n`;
                            reportContent += `|-------|--------|-------|----------|\n`;
                            
                            for (const check of detailed.Checks) {
                              const checkIcon = check.Status === 'Passed' ? '‚úÖ' : 
                                              check.Status === 'Warning' ? '‚ö†Ô∏è' : 
                                              check.Status === 'Skipped' ? '‚è≠Ô∏è' : '‚ùå';
                              // Escape findings to prevent markdown/HTML breaking
                              let findings = 'None';
                              if (check.Findings && check.Findings.length > 0) {
                                findings = check.Findings.slice(0, 2)
                                  .map(f => f.replace(/[|<>]/g, match => {
                                    // Escape pipe, less than, greater than
                                    return {'|': '\\|', '<': '&lt;', '>': '&gt;'}[match];
                                  }))
                                  .join('<br>');
                              }
                              reportContent += `| ${checkIcon} ${check.CheckName} | ${check.Status} | ${check.Score}% | ${findings} |\n`;
                            }
                            
                            // Add actionable recommendations
                            const failedChecks = detailed.Checks.filter(c => c.Status === 'Failed' || c.Status === 'Warning');
                            if (failedChecks.length > 0) {
                              reportContent += `\n#### üí° Recommended Actions\n\n`;
                              for (const check of failedChecks) {
                                if (check.Findings && check.Findings.length > 0) {
                                  reportContent += `**${check.CheckName}:**\n`;
                                  for (const finding of check.Findings) {
                                    reportContent += `- ${finding}\n`;
                                  }
                                }
                              }
                            }
                          }
                        } catch (err) {
                          reportContent += `*Unable to load detailed findings: ${err.message}*\n`;
                        }
                      }
                      
                      reportContent += `\n</details>\n\n`;
                    }
                  }
                  
                  // Quick Actions section
                  reportContent += `### üöÄ Quick Actions\n\n`;
                  if (summary.OverallStatus === 'Failed' || summary.Warnings > 0) {
                    reportContent += `1. üì• **Download** [detailed reports](${runUrl}) from workflow artifacts\n`;
                    reportContent += `2. üîß **Fix** issues identified in the findings above\n`;
                    reportContent += `3. üß™ **Test locally**: \`./aitherzero 0420 -Path <file>\`\n`;
                    reportContent += `4. ‚ôªÔ∏è **Push** changes to re-run validation\n\n`;
                  } else {
                    reportContent += `‚ú® **All quality checks passed!** Your code meets our quality standards.\n\n`;
                  }
                  
                  // Quality Standards Reference
                  reportContent += `### üìö Quality Standards\n\n`;
                  reportContent += `- **Error Handling**: Proper try/catch blocks, error logging\n`;
                  reportContent += `- **Logging**: Appropriate logging at different levels\n`;
                  reportContent += `- **Test Coverage**: Corresponding test files exist\n`;
                  reportContent += `- **PSScriptAnalyzer**: No critical issues\n`;
                  reportContent += `- **Documentation**: Function help and comments\n\n`;
                  reportContent += `üìñ [View Quality Guidelines](${repoUrl}/blob/main/docs/QUALITY-QUICK-REFERENCE.md)\n\n`;
                  
                } else {
                  reportContent += '‚ö†Ô∏è No quality reports found.\n';
                }
              } else {
                reportContent += '‚ö†Ô∏è Reports directory not found.\n';
              }
            } catch (error) {
              reportContent += `‚ö†Ô∏è Error reading reports: ${error.message}\n`;
              console.error('Error generating quality report:', error);
            }
            
            reportContent += `---\n`;
            reportContent += `üìä [View Dashboard](https://wizzense.github.io/AitherZero/reports/dashboard.html) | `;
            reportContent += `üìÅ [Detailed Reports](${runUrl}) | `;
            reportContent += `üîÑ [Workflow Run](${runUrl})\n`;
            
            // Find and update existing comment or create new one
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber
            });
            
            const botComment = comments.find(c => 
              c.user.login === 'github-actions[bot]' && 
              c.body.includes('üîç Quality Validation Report')
            );
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: reportContent
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body: reportContent
              });
            }

      - name: üìã Create Issues for Quality Failures
        if: steps.validation.outputs.exit-code != '0' && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // Read quality reports
            const reportsDir = './reports/quality';
            
            try {
              if (!fs.existsSync(reportsDir)) {
                console.log('No reports directory found');
                return;
              }
              
              const summaryFiles = fs.readdirSync(reportsDir)
                .filter(f => f.endsWith('-summary.json'));
              
              if (summaryFiles.length === 0) {
                console.log('No summary files found');
                return;
              }
              
              const summaryPath = path.join(reportsDir, summaryFiles[0]);
              const summary = JSON.parse(fs.readFileSync(summaryPath, 'utf8'));
              
              // Only create issue if there are failed files
              if (!summary.Files || summary.Failed === 0) {
                console.log('No failed files to report');
                return;
              }
              
              // Read detailed reports for failed files
              const failedFiles = Array.isArray(summary.Files) 
                ? summary.Files.filter(f => f.Status === 'Failed')
                : (summary.Files.Status === 'Failed' ? [summary.Files] : []);
              
              if (failedFiles.length === 0) {
                console.log('No failed files found in details');
                return;
              }
              
              // Create issue for each failed file or one consolidated issue
              for (const file of failedFiles) {
                const fileName = path.basename(file.FilePath);
                
                // Find the detailed report
                const detailedReportFiles = fs.readdirSync(reportsDir)
                  .filter(f => f.includes(fileName.replace(/\.(ps1|psm1|psd1)$/, '')) && f.endsWith('.txt'));
                
                let detailedFindings = '';
                if (detailedReportFiles.length > 0) {
                  const reportPath = path.join(reportsDir, detailedReportFiles[0]);
                  const reportContent = fs.readFileSync(reportPath, 'utf8');
                  
                  // Extract the detailed results section
                  const match = reportContent.match(/DETAILED RESULTS[\s\S]*?={50,}/);
                  if (match) {
                    detailedFindings = match[0].replace(/={50,}/, '').trim();
                  }
                }
                
                const issueTitle = 'Quality Validation Failed: ' + fileName + ' (Score: ' + file.Score + '%)';
                const prNumber = context.payload.pull_request?.number || 'N/A';
                const runUrl = `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
                const issueBody = '## Quality Validation Failure Report\n\n' +
                  '**File**: `' + file.FilePath + '`\n' +
                  '**Overall Score**: ' + file.Score + '%\n' +
                  '**Status**: ' + file.Status + '\n' +
                  '**PR**: #' + prNumber + '\n\n' +
                  '### Summary\n' +
                  'This file failed quality validation checks. Please review the findings below and address the issues.\n\n' +
                  '### Detailed Findings\n\n' +
                  '```\n' +
                  (detailedFindings || 'See workflow artifacts for full details') + '\n' +
                  '```\n\n' +
                  '### Next Steps\n' +
                  '1. Review the quality validation report in the [workflow artifacts](' + runUrl + ')\n' +
                  '2. Address the issues identified in the findings\n' +
                  '3. Run local validation: `./aitherzero 0420 -Path ' + file.FilePath + '`\n' +
                  '4. Re-run validation after fixes\n\n' +
                  '@copilot please review this file and address the quality issues identified above.\n\n' +
                  '---\n' +
                  '*This issue was automatically created by the Quality Validation System*\n' +
                  '*Related PR: #${{ github.event.pull_request.number }}*\n' +
                  '*Workflow Run: [${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})*';
                
                // Create the issue
                const issue = await github.rest.issues.create({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  title: issueTitle,
                  body: issueBody,
                  labels: ['quality-validation', 'automated', 'needs-fix']
                  # Note: Cannot assign to @copilot as it's not a regular user
                  # Instead, we mention @copilot in the issue body (line 439)
                });
                
                console.log(`Created issue #${issue.data.number} for ${fileName}`);
                
                // Link issue to PR by adding a comment
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: context.payload.pull_request.number,
                  body: `üìã Created issue #${issue.data.number} to track quality validation failures for \`${fileName}\``
                });
              }
              
            } catch (error) {
              console.error('Error creating quality issues:', error);
              core.setFailed(`Failed to create quality issues: ${error.message}`);
            }

      - name: ‚ùå Fail if Quality Check Failed
        if: steps.validation.outputs.exit-code != '0'
        run: |
          echo "::error::Quality validation failed. Please review the reports and address the issues."
          exit 1

      - name: ‚úÖ Quality Validation Summary
        if: always()
        shell: pwsh
        run: |
          Write-Host "`n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó" -ForegroundColor Cyan
          Write-Host "‚ïë              QUALITY VALIDATION SUMMARY                      ‚ïë" -ForegroundColor Cyan
          Write-Host "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù" -ForegroundColor Cyan
          
          $hasFiles = "${{ steps.changes.outputs.has-files }}"
          $exitCode = "${{ steps.validation.outputs.exit-code }}"
          
          if ($hasFiles -eq "false") {
            Write-Host "`n‚ö†Ô∏è No PowerShell files found to validate" -ForegroundColor Yellow
          } elseif ($exitCode -eq "0") {
            Write-Host "`n‚úÖ All quality checks PASSED" -ForegroundColor Green
          } else {
            Write-Host "`n‚ùå Quality checks FAILED" -ForegroundColor Red
          }
          
          Write-Host "`nüìä View detailed reports in workflow artifacts" -ForegroundColor Cyan
