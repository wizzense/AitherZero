---
name: Intelligent CI Orchestrator

# Smart CI/CD orchestration optimized for AI agents and cost efficiency
on:
  push:
    branches: [main, develop, 'feature/**', 'copilot/**']
    paths-ignore:
      - '**.md'
      - 'docs/**'
      - '.gitignore'
      - 'LICENSE'
      - '.github/ISSUE_TEMPLATE/**'
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]
    paths-ignore:
      - '**.md'
      - 'docs/**'
      - '.gitignore' 
      - 'LICENSE'
      - '.github/ISSUE_TEMPLATE/**'
  workflow_dispatch:
    inputs:
      test_scope:
        description: 'Test scope'
        type: choice
        options: ['quick', 'standard', 'comprehensive']
        default: 'quick'
      force_full_analysis:
        description: 'Force full analysis regardless of changes'
        type: boolean
        default: false

# Cost-optimized concurrency - prevent redundant runs
concurrency:
  group: intelligent-ci-${{ github.event.pull_request.number || github.ref_name }}
  cancel-in-progress: true

permissions:
  contents: read
  checks: write
  pull-requests: write
  issues: write
  actions: read

env:
  AITHERZERO_CI: true
  AITHERZERO_NONINTERACTIVE: true
  # AI Agent coordination
  AI_AGENT_MODE: true
  CI_OPTIMIZATION_LEVEL: 'aggressive'

jobs:
  # Smart change detection to determine what needs to run
  change-detection:
    name: üß† Smart Change Detection
    runs-on: ubuntu-latest
    outputs:
      needs-core-validation: ${{ steps.detect.outputs.needs-core-validation }}
      needs-security-scan: ${{ steps.detect.outputs.needs-security-scan }}
      needs-full-tests: ${{ steps.detect.outputs.needs-full-tests }}
      needs-performance-tests: ${{ steps.detect.outputs.needs-performance-tests }}
      changed-areas: ${{ steps.detect.outputs.changed-areas }}
      optimization-level: ${{ steps.detect.outputs.optimization-level }}
      
    steps:
      - name: üì• Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Need full history for accurate change detection
          
      - name: üîç Intelligent Change Analysis
        id: detect
        shell: pwsh
        run: |
          # Smart change detection based on file patterns and impact analysis
          $changedFiles = @()
          $needsCoreValidation = $false
          $needsSecurityScan = $false
          $needsFullTests = $false
          $needsPerformanceTests = $false
          $changedAreas = @()
          
          # Get changed files with error handling
          $changedFiles = @()
          try {
            if ($env:GITHUB_EVENT_NAME -eq 'pull_request') {
              # For pull requests, compare with the base branch
              $changedFiles = git diff --name-only $env:GITHUB_BASE_REF...HEAD 2>$null
              if ($LASTEXITCODE -ne 0) {
                # Fallback: use GitHub's files API approach
                $changedFiles = git diff --name-only HEAD~1..HEAD 2>$null
              }
            } else {
              # For push events, compare with previous commit
              $changedFiles = git diff --name-only HEAD~1..HEAD 2>$null
            }
          } catch {
            Write-Host "‚ö†Ô∏è Git diff failed, assuming all files changed for safety" -ForegroundColor Yellow
            $changedFiles = @('**/*')  # Trigger full validation as fallback
          }
          
          # Ensure we have an array
          if (-not $changedFiles) { $changedFiles = @() }
          
          Write-Host "üìã Changed files detected:" -ForegroundColor Cyan
          $changedFiles | ForEach-Object { Write-Host "  ‚Ä¢ $_" }
          
          # Analyze impact
          foreach ($file in $changedFiles) {
            switch -Regex ($file) {
              # Critical infrastructure - always needs full validation
              '^(\.github/workflows/|automation-scripts/|bootstrap\.ps1|Start-AitherZero\.ps1)' {
                $needsCoreValidation = $true
                $needsFullTests = $true
                $needsSecurityScan = $true  # Infrastructure changes need security review
                $changedAreas += 'infrastructure'
              }
              
              # Security-sensitive files - always need security scan
              '^(domains/security/|.*[Ss]ecurity.*|.*[Aa]uth.*|.*[Cc]red.*\.ps1)' {
                $needsSecurityScan = $true
                $needsCoreValidation = $true
                $changedAreas += 'security'
              }
              
              # Performance-critical components
              '^(domains/automation/|.*[Pp]erformance.*|.*[Oo]rchestration.*)' {
                $needsPerformanceTests = $true
                $needsSecurityScan = $true  # Automation code needs security review
                $changedAreas += 'performance'
              }
              
              # Core modules - need security scan for PowerShell code
              '^domains/.*\.(ps1|psm1)$' {
                $needsCoreValidation = $true
                $needsSecurityScan = $true  # All PowerShell code needs security review
                $changedAreas += 'core'
              }
              
              # Automation scripts - need security scan
              '^automation-scripts/.*\.ps1$' {
                $needsCoreValidation = $true
                $needsSecurityScan = $true  # All automation scripts need security review
                $changedAreas += 'automation'
              }
              
              # Test changes
              '^tests/' {
                $needsCoreValidation = $true
                $changedAreas += 'testing'
              }
              
              # Any PowerShell file - needs basic security scan
              '\.(ps1|psm1|psd1)$' {
                $needsSecurityScan = $true  # All PowerShell files need security review
                if (-not ($changedAreas -contains 'powershell')) {
                  $changedAreas += 'powershell'
                }
              }
            }
          }
          
          # Determine optimization level
          $optimizationLevel = 'standard'
          if ($changedFiles.Count -lt 5 -and -not $needsFullTests) {
            $optimizationLevel = 'aggressive'
          } elseif ($needsPerformanceTests -or $changedFiles.Count -gt 20) {
            $optimizationLevel = 'conservative'
          }
          
          # Force full analysis if requested
          if ('${{ github.event.inputs.force_full_analysis }}' -eq 'true') {
            $needsCoreValidation = $true
            $needsSecurityScan = $true
            $needsFullTests = $true
            $optimizationLevel = 'conservative'
          }
          
          # Set outputs
          "needs-core-validation=$needsCoreValidation" | Out-File -FilePath $env:GITHUB_OUTPUT -Append
          "needs-security-scan=$needsSecurityScan" | Out-File -FilePath $env:GITHUB_OUTPUT -Append
          "needs-full-tests=$needsFullTests" | Out-File -FilePath $env:GITHUB_OUTPUT -Append  
          "needs-performance-tests=$needsPerformanceTests" | Out-File -FilePath $env:GITHUB_OUTPUT -Append
          "changed-areas=$($changedAreas -join ',')" | Out-File -FilePath $env:GITHUB_OUTPUT -Append
          "optimization-level=$optimizationLevel" | Out-File -FilePath $env:GITHUB_OUTPUT -Append
          
          Write-Host "üéØ Analysis Results:" -ForegroundColor Green
          Write-Host "  Core Validation: $needsCoreValidation"
          Write-Host "  Security Scan: $needsSecurityScan"
          Write-Host "  Full Tests: $needsFullTests"
          Write-Host "  Performance Tests: $needsPerformanceTests"
          Write-Host "  Changed Areas: $($changedAreas -join ', ')"
          Write-Host "  Optimization Level: $optimizationLevel"

  # Always run - fast feedback (< 2 minutes)
  quick-validation:
    name: ‚ö° Quick Validation
    runs-on: ubuntu-latest
    needs: change-detection
    
    steps:
      - name: üì• Checkout
        uses: actions/checkout@v4
        
      - name: ‚ö° Quick Syntax Check
        shell: pwsh
        run: |
          Write-Host "üîç Running quick syntax validation..." -ForegroundColor Cyan
          
          # Run validation and capture result via process exit code
          $process = Start-Process -FilePath "pwsh" -ArgumentList @("-Command", "& './Start-AitherZero.ps1' -Mode Orchestrate -Sequence '0407' -NonInteractive") -Wait -PassThru -NoNewWindow
          
          if ($process.ExitCode -eq 0) {
            Write-Host "‚úÖ Quick syntax validation completed successfully!" -ForegroundColor Green
          } else {
            Write-Error "Quick syntax validation failed with exit code: $($process.ExitCode)"
            exit $process.ExitCode
          }

  # Conditional - run based on change detection
  core-validation:
    name: üîç Core Validation  
    runs-on: ubuntu-latest
    needs: [change-detection, quick-validation]
    if: needs.change-detection.outputs.needs-core-validation == 'true'
    
    steps:
      - name: üì• Checkout
        uses: actions/checkout@v4
        
      - name: üîç Core Analysis
        shell: pwsh
        run: |
          Write-Host "üîç Running core validation..." -ForegroundColor Cyan
          
          # Run comprehensive PSScriptAnalyzer analysis with full fidelity
          Write-Host "Running PSScriptAnalyzer with full analysis..." -ForegroundColor Yellow
          
          try {
            $process1 = Start-Process -FilePath "pwsh" -ArgumentList @("-Command", "& './Start-AitherZero.ps1' -Mode Orchestrate -Sequence '0404' -NonInteractive") -Wait -PassThru -NoNewWindow
            Write-Host "PSScriptAnalyzer completed with exit code: $($process1.ExitCode)" -ForegroundColor $(if ($process1.ExitCode -eq 0) { 'Green' } elseif ($process1.ExitCode -eq 1) { 'Yellow' } else { 'Red' })
            
            # Report all findings - don't hide issues
            if ($process1.ExitCode -ne 0) {
              Write-Host "‚ö†Ô∏è PSScriptAnalyzer found issues (exit code: $($process1.ExitCode))" -ForegroundColor Yellow
              Write-Host "Issues will be reported in the generated reports for review" -ForegroundColor Yellow
            }
          } catch {
            Write-Error "PSScriptAnalyzer encountered a critical error: $($_.Exception.Message)"
            throw
          }
          
          # Generate comprehensive report for analysis
          Write-Host "Generating project report..." -ForegroundColor Yellow
          try {
            $process2 = Start-Process -FilePath "pwsh" -ArgumentList @("-Command", "& './Start-AitherZero.ps1' -Mode Orchestrate -Sequence '0510' -NonInteractive") -Wait -PassThru -NoNewWindow
            if ($process2.ExitCode -eq 0) {
              Write-Host "‚úÖ Project report generated successfully!" -ForegroundColor Green
            } else {
              Write-Warning "Project report generation completed with warnings (exit code: $($process2.ExitCode))"
            }
          } catch {
            Write-Warning "Project report generation encountered an issue: $($_.Exception.Message)"
          }
          
          Write-Host "‚úÖ Core validation completed!" -ForegroundColor Green
          
      - name: üìä Upload Analysis Results
        uses: actions/upload-artifact@v4
        with:
          name: core-analysis-results
          path: |
            tests/analysis/
            tests/reports/
          retention-days: 30

  # Security-focused validation
  security-validation:
    name: üîí Security Validation
    runs-on: ubuntu-latest
    needs: [change-detection, quick-validation]
    if: needs.change-detection.outputs.needs-security-scan == 'true'
    
    steps:
      - name: üì• Checkout
        uses: actions/checkout@v4
        
      - name: üîí Security Analysis
        shell: pwsh
        run: |
          Write-Host "üîí Running security analysis..." -ForegroundColor Cyan
          
          # Run security-focused scripts
          $process = Start-Process -FilePath "pwsh" -ArgumentList @("-Command", "& './Start-AitherZero.ps1' -Mode Orchestrate -Sequence '0523' -NonInteractive") -Wait -PassThru -NoNewWindow
          
          Write-Host "Security analysis completed with exit code: $($process.ExitCode)" -ForegroundColor $(if ($process.ExitCode -eq 0) { 'Green' } else { 'Yellow' })
          
          if ($process.ExitCode -eq 0) {
            Write-Host "‚úÖ No critical security issues found!" -ForegroundColor Green
          } elseif ($process.ExitCode -eq 1) {
            Write-Host "‚ö†Ô∏è Security issues detected - see detailed report" -ForegroundColor Yellow
            Write-Host "üìã Security findings are captured in reports for review" -ForegroundColor Cyan
            Write-Host "üí° Security issues are reported for attention - they don't block CI but require review" -ForegroundColor Blue
          } else {
            Write-Host "‚ùå Security analysis encountered errors (exit code: $($process.ExitCode))" -ForegroundColor Red
            exit $process.ExitCode
          }
          
          # Always exit 0 for security findings (exit code 1), only fail on actual errors (exit code > 1)
          if ($process.ExitCode -le 1) {
            exit 0
          } else {
            exit $process.ExitCode
          }
          
      - name: üìä Upload Security Results
        uses: actions/upload-artifact@v4
        with:
          name: security-analysis-results
          path: |
            reports/tech-debt/analysis/
            tests/analysis/
            security-reports/
            *.json
          retention-days: 60

  # Comprehensive testing - parallelized by priority and category for faster execution
  comprehensive-tests:
    name: üß™ Tests - ${{ matrix.category }} (P${{ matrix.priority }})
    runs-on: ubuntu-latest
    needs: [change-detection, core-validation]
    if: needs.change-detection.outputs.needs-full-tests == 'true'
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      max-parallel: 6
      matrix:
        include:
          # Priority 1: Core functionality (fastest, most critical)
          - category: "Core Domain Tests"
            priority: 1
            test_path: "tests/domains"
            test_scope: "core"
            timeout: 10
            
          - category: "Core Unit Tests" 
            priority: 1
            test_path: "tests/unit/AitherZero.Tests.ps1,tests/unit/Configuration.Tests.ps1,tests/unit/Start-AitherZero.Tests.ps1"
            test_scope: "core"
            timeout: 10
            
          # Priority 2: Infrastructure & Setup (0000-0199)
          - category: "Infrastructure Tests"
            priority: 2
            test_path: "tests/unit/automation-scripts/0000-0099,tests/unit/automation-scripts/0100-0199"
            test_scope: "infrastructure"
            timeout: 15
            
          # Priority 3: Development Tools (0200-0299)  
          - category: "Development Tests"
            priority: 3
            test_path: "tests/unit/automation-scripts/0200-0299"
            test_scope: "development"
            timeout: 15
            
          # Priority 4: Testing & Validation (0400-0499)
          - category: "Testing Framework Tests"
            priority: 2
            test_path: "tests/unit/automation-scripts/0400-0499"
            test_scope: "testing"
            timeout: 15
            
          # Priority 5: Reporting & Analysis (0500-0599)
          - category: "Reporting Tests" 
            priority: 4
            test_path: "tests/unit/automation-scripts/0500-0599"
            test_scope: "reporting"
            timeout: 15
            
          # Priority 6: Git & CI/CD (0700-0799)
          - category: "CI/CD Tests"
            priority: 3
            test_path: "tests/unit/automation-scripts/0700-0799"
            test_scope: "cicd"
            timeout: 15
            
          # Priority 7: Integration Tests
          - category: "Integration Tests"
            priority: 4
            test_path: "tests/integration"
            test_scope: "integration"
            timeout: 15
    
    steps:
      - name: üì• Checkout  
        uses: actions/checkout@v4
        
      - name: üß™ Run ${{ matrix.category }}
        shell: pwsh
        timeout-minutes: ${{ matrix.timeout }}
        run: |
          Write-Host "üß™ Running ${{ matrix.category }} (Priority ${{ matrix.priority }})..." -ForegroundColor Cyan
          Write-Host "üìÅ Test Path: ${{ matrix.test_path }}" -ForegroundColor Gray
          
          # Determine test execution strategy
          $testPath = "${{ matrix.test_path }}"
          $totalTests = 0
          $totalPassed = 0
          $totalFailed = 0
          
          # Simple direct Pester execution for cleaner output
          if ($testPath -match ',') {
            $testFiles = $testPath -split ',' | ForEach-Object { $_.Trim() }
            Write-Host "üîç Running $($testFiles.Count) test file(s)/path(s)" -ForegroundColor Yellow
            
            foreach ($path in $testFiles) {
              if (Test-Path $path) {
                Write-Host "`n  ‚ñ∂Ô∏è Testing: $path" -ForegroundColor Cyan
                
                try {
                  # Direct Pester execution with minimal overhead
                  Import-Module Pester -Force -MinimumVersion 5.0
                  $config = New-PesterConfiguration
                  $config.Run.Path = $path
                  $config.Run.PassThru = $true
                  $config.Output.Verbosity = 'Normal'
                  $config.Should.ErrorAction = 'Continue'
                  
                  $result = Invoke-Pester -Configuration $config
                  
                  Write-Host "     üìä Found: $($result.TotalCount) tests, Passed: $($result.PassedCount), Failed: $($result.FailedCount)" -ForegroundColor Gray
                  
                  if ($result.FailedCount -eq 0) {
                    Write-Host "     ‚úÖ PASSED" -ForegroundColor Green
                    $totalPassed++
                  } else {
                    Write-Host "     ‚ùå FAILED ($($result.FailedCount) failures)" -ForegroundColor Red
                    $totalFailed++
                    
                    # Show failed test names
                    if ($result.Failed.Count -gt 0) {
                      Write-Host "     Failed Tests:" -ForegroundColor Red
                      $result.Failed | Select-Object -First 3 | ForEach-Object {
                        Write-Host "       - $($_.ExpandedName)" -ForegroundColor DarkRed
                      }
                      if ($result.Failed.Count -gt 3) {
                        Write-Host "       ... and $($result.Failed.Count - 3) more" -ForegroundColor DarkRed
                      }
                    }
                  }
                  $totalTests++
                } catch {
                  Write-Host "     ‚ùå ERROR: $_" -ForegroundColor Red
                  $totalFailed++
                  $totalTests++
                }
                
              } else {
                Write-Host "  ‚è≠Ô∏è Skipped: $path (not found)" -ForegroundColor Yellow
              }
            }
            
          } else {
            # Single path execution
            if (Test-Path $testPath) {
              Write-Host "üîç Running test directory: $testPath" -ForegroundColor Yellow
              
              try {
                # Direct Pester execution
                Import-Module Pester -Force -MinimumVersion 5.0
                $config = New-PesterConfiguration
                $config.Run.Path = $testPath
                $config.Run.PassThru = $true
                $config.Output.Verbosity = 'Normal'
                $config.Should.ErrorAction = 'Continue'
                
                $result = Invoke-Pester -Configuration $config
                
                Write-Host "  üìä Found: $($result.TotalCount) tests, Passed: $($result.PassedCount), Failed: $($result.FailedCount)" -ForegroundColor Gray
                
                if ($result.FailedCount -eq 0) {
                  $totalPassed = 1
                  $totalFailed = 0
                } else {
                  $totalPassed = 0
                  $totalFailed = 1
                  
                  # Show failed test names
                  if ($result.Failed.Count -gt 0) {
                    Write-Host "  Failed Tests:" -ForegroundColor Red
                    $result.Failed | Select-Object -First 5 | ForEach-Object {
                      Write-Host "    - $($_.ExpandedName)" -ForegroundColor DarkRed
                    }
                    if ($result.Failed.Count -gt 5) {
                      Write-Host "    ... and $($result.Failed.Count - 5) more" -ForegroundColor DarkRed
                    }
                  }
                }
                $totalTests = 1
              } catch {
                Write-Host "  ‚ùå ERROR: $_" -ForegroundColor Red
                $totalFailed = 1
                $totalTests = 1
              }
              
            } else {
              Write-Host "‚è≠Ô∏è Test path not found: $testPath - no tests to run" -ForegroundColor Yellow
            }
          }
          
          # Display final summary
          Write-Host "`nüìä ${{ matrix.category }} Summary:" -ForegroundColor Cyan
          Write-Host "   Test Paths: $totalTests" -ForegroundColor White
          Write-Host "   Passed: $totalPassed" -ForegroundColor Green
          Write-Host "   Failed: $totalFailed" -ForegroundColor $(if ($totalFailed -eq 0) { 'Green' } else { 'Red' })
          
          if ($totalFailed -eq 0 -and $totalTests -gt 0) {
            Write-Host "‚úÖ All ${{ matrix.category }} tests passed!" -ForegroundColor Green
          } elseif ($totalTests -eq 0) {
            Write-Host "‚è≠Ô∏è No tests found for ${{ matrix.category }}" -ForegroundColor Yellow
          } else {
            Write-Host "‚ö†Ô∏è Some ${{ matrix.category }} tests failed - check details above" -ForegroundColor Yellow
          }
          
          # Always exit 0 to not block CI - test failures are reported via artifacts
          exit 0
          
      - name: üìä Upload ${{ matrix.category }} Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.test_scope }}-p${{ matrix.priority }}
          path: |
            tests/results/
            tests/reports/
            logs/
          retention-days: 30

  # Comprehensive tests - legacy single job (fallback option)
  comprehensive-tests-legacy:
    name: üß™ All Tests (Legacy Mode)
    runs-on: ubuntu-latest
    needs: [change-detection, core-validation]
    if: needs.change-detection.outputs.needs-full-tests == 'true' && github.event.inputs.force_full_analysis == 'true'
    timeout-minutes: 45
    
    steps:
      - name: üì• Checkout  
        uses: actions/checkout@v4
        
      - name: üß™ Run All Comprehensive Tests
        shell: pwsh
        run: |
          Write-Host "üß™ Running ALL comprehensive tests in legacy mode..." -ForegroundColor Cyan
          Write-Host "‚ö†Ô∏è This is slower than the parallelized matrix approach" -ForegroundColor Yellow
          
          # Run full test suite - all tests in one execution
          $env:AITHERZERO_TEST_SCOPE = "full"
          $process = Start-Process -FilePath "pwsh" -ArgumentList @("-Command", "& './Start-AitherZero.ps1' -Mode Orchestrate -Sequence '0402' -NonInteractive") -Wait -PassThru -NoNewWindow
          
          Write-Host "Test execution completed with exit code: $($process.ExitCode)" -ForegroundColor $(if ($process.ExitCode -eq 0) { 'Green' } else { 'Yellow' })
          
          if ($process.ExitCode -eq 0) {
            Write-Host "‚úÖ All comprehensive tests passed!" -ForegroundColor Green
          } else {
            Write-Host "‚ö†Ô∏è Test failures detected (exit code: $($process.ExitCode))" -ForegroundColor Yellow
            Write-Host "üìã Complete test results and failure details are captured in reports" -ForegroundColor Cyan
            Write-Host "üí° Test failures are reported for review - they don't block CI but require attention" -ForegroundColor Blue
          }
          
          # Always exit 0 to not block CI
          exit 0
          
      - name: üìä Upload All Test Results
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-test-results-legacy
          path: |
            tests/results/
            tests/reports/
          retention-days: 30

  # Multi-platform validation - for main/develop/copilot branches or when explicitly requested
  cross-platform:
    name: üåç Cross-Platform (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    needs: [change-detection, core-validation]
    if: (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop' || startsWith(github.ref, 'refs/heads/copilot/') || github.event.inputs.force_full_analysis == 'true') && needs.change-detection.outputs.needs-core-validation == 'true'
    
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        
    steps:
      - name: üì• Checkout
        uses: actions/checkout@v4
        
      - name: üåç Platform Validation
        shell: pwsh
        run: |
          Write-Host "üåç Running platform-specific validation on ${{ matrix.os }}..." -ForegroundColor Cyan
          
          # Quick validation for cross-platform compatibility
          $process = Start-Process -FilePath "pwsh" -ArgumentList @("-Command", "& './Start-AitherZero.ps1' -Mode Orchestrate -Sequence '0407' -NonInteractive") -Wait -PassThru -NoNewWindow
          if ($process.ExitCode -eq 0) {
            Write-Host "‚úÖ Platform validation completed successfully!" -ForegroundColor Green
          } else {
            Write-Error "Platform validation failed with exit code: $($process.ExitCode)"
            exit $process.ExitCode
          }
          
      - name: üìä Upload Platform Results
        uses: actions/upload-artifact@v4
        with:
          name: platform-results-${{ matrix.os }}
          path: |
            tests/results/
          retention-days: 14

  # Final validation - consolidate results
  validation-summary:
    name: üìã Validation Summary
    runs-on: ubuntu-latest
    needs: [change-detection, quick-validation, core-validation, comprehensive-tests, comprehensive-tests-legacy]
    if: always() && needs.change-detection.result == 'success'
    
    steps:
      - name: üì• Checkout
        uses: actions/checkout@v4
        
      - name: üìä Download All Results
        uses: actions/download-artifact@v4
        with:
          path: ./ci-results
        continue-on-error: true
        
      - name: üìã Generate CI Summary
        shell: pwsh
        run: |
          Write-Host "üìã Generating CI validation summary..." -ForegroundColor Cyan
          
          $summary = @{
            Timestamp = Get-Date -Format 'yyyy-MM-dd HH:mm:ss'
            GitRef = $env:GITHUB_REF
            GitSha = $env:GITHUB_SHA
            WorkflowRun = $env:GITHUB_RUN_ID
            ChangeDetection = @{
              NeedsCoreValidation = '${{ needs.change-detection.outputs.needs-core-validation }}'
              NeedsSecurityScan = '${{ needs.change-detection.outputs.needs-security-scan }}'
              NeedsFullTests = '${{ needs.change-detection.outputs.needs-full-tests }}'
              ChangedAreas = '${{ needs.change-detection.outputs.changed-areas }}'
              OptimizationLevel = '${{ needs.change-detection.outputs.optimization-level }}'
            }
            JobResults = @{
              QuickValidation = '${{ needs.quick-validation.result }}'
              CoreValidation = '${{ needs.core-validation.result }}'
              ComprehensiveTests = '${{ needs.comprehensive-tests.result }}'
              ComprehensiveTestsLegacy = '${{ needs.comprehensive-tests-legacy.result }}'
            }
            TestMatrix = @{
              Strategy = "Parallelized by Priority & Category"
              Categories = @(
                "Core Domain Tests (P1)", "Core Unit Tests (P1)", 
                "Infrastructure Tests (P2)", "Testing Framework Tests (P2)",
                "Development Tests (P3)", "CI/CD Tests (P3)",
                "Reporting Tests (P4)", "Integration Tests (P4)"
              )
              Benefits = "Faster execution, better resource utilization, priority-based failure detection"
            }
          }
          
          $summaryJson = $summary | ConvertTo-Json -Depth 5
          $summaryJson | Out-File "ci-summary.json"
          
          Write-Host "üìä CI Summary:" -ForegroundColor Green
          Write-Host $summaryJson
          
      - name: ü§ñ Trigger AI Agent Coordination
        if: github.event_name == 'pull_request' && (needs.core-validation.result == 'failure' || needs.comprehensive-tests.result == 'failure')
        uses: actions/github-script@v7
        with:
          script: |
            console.log('Triggering AI Agent Coordinator due to CI issues...');
            
            // Determine priority based on failure severity
            let priority = 'normal';
            const coreValidationFailed = '${{ needs.core-validation.result }}' === 'failure';
            const testsFailed = '${{ needs.comprehensive-tests.result }}' === 'failure';
            
            if (coreValidationFailed && testsFailed) {
              priority = 'high';
            } else if (coreValidationFailed || testsFailed) {
              priority = 'normal';
            }
            
            // Determine agent type based on what failed
            let agentType = 'code-review';
            if (testsFailed && !coreValidationFailed) {
              agentType = 'testing';
            }
            
            console.log(`AI Agent coordination will be triggered with priority: ${priority}, agent type: ${agentType}`);
            
            try {
              // Trigger the AI Agent Coordinator workflow
              const response = await github.rest.actions.createWorkflowDispatch({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: 'ai-agent-coordinator.yml',
                ref: context.ref,
                inputs: {
                  priority: priority,
                  agent_type: agentType,
                  target_branch: context.ref.replace('refs/heads/', '')
                }
              });
              
              console.log('‚úÖ AI Agent Coordinator workflow triggered successfully');
              
              // Add a comment to the PR about the coordination
              if (context.payload.pull_request) {
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: context.payload.pull_request.number,
                  body: `## ü§ñ AI Agent Coordination Triggered

The Intelligent CI detected issues and has automatically triggered the AI Agent Coordinator for advanced analysis and issue resolution.

**Priority Level:** ${priority}
**Focus Area:** ${agentType === 'testing' ? 'Test Failures' : 'Code Quality Issues'}

The AI Agent Coordinator will:
- Run detailed analysis of the detected issues
- Create specific GitHub issues for problems found
- Provide actionable recommendations for fixes

üìä [View CI Results](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})

---
*This coordination was automatically triggered by the Intelligent CI Orchestrator*`
                });
              }
            } catch (error) {
              console.log('‚ö†Ô∏è Could not trigger AI Agent Coordinator:', error.message);
              // Don't fail the workflow if coordination fails
            }
          
      - name: üìä Upload CI Summary
        uses: actions/upload-artifact@v4
        with:
          name: ci-validation-summary
          path: ci-summary.json
          retention-days: 90